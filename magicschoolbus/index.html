# How to build AI product sense

The secret is using Cursor for non-technical work

You're in a product meeting and someone mentions 'subagents' or 'context engineering' or 'agent memory.' You nod along. You know what these terms mean‚Ä¶ you're just hoping no one expects you to use them in a sentence.

You've watched the video explainers, bookmarked the infographics, vibe coded a few apps, and even shipped an AI feature. So why does it still feel like you're miles from truly understanding all this stuff?

We (Tal and Aman) have both been there, over and over again while building AI products for tens of thousands of customers. The problem isn't you. The problem is the "AI hype-industrial complex." Most AI content is designed to induce FOMO, not to teach you: 'this model is INSANE' posts, demos that hide the messy reality, and diagrams that complicate more than they explain.

We found that our single most transformative habit to internalize important AI concepts and build "AI product sense" was to move away from consumer grade UIs (ChatGPT, Granola, Lovable) and into more powerful AI coding agents like Cursor and Claude Code.

Having good AI product sense means correctly anticipating what will be truly impactful for your users while also being feasible with AI. It's recognizing context rot when reading support tickets about AI "forgetting" key facts‚Äîand coming up with ways to smartly prune the context. Or watching a user struggle through a workflow in testing and confidently saying that agent memory solves this‚Äîand knowing how to structure it.

We've learned more in the last 3 months by using Cursor for daily (non-technical) tasks than in 3 years of using ChatGPT. Why? Because coding agents transparently show their work. You can read AI's reasoning, inspect the tool calls, and watch the context window fill up. You hit the same walls as engineers building AI applications, naturally intuit your own solutions, and start anticipating trends and industry announcements.

We now spend our days using Cursor (and Claude Code) for daily, non-technical work: strategy, prioritization, decision making, data analysis, and productivity. They serve as our thinking partner and personal operating system.

In this post, we'll guide you through using AI coding agents for your non-technical product work:

- In steps 1-4 we'll get set up and familiar with Cursor with a fun Disney-themed exercise
- In steps 5-6 we'll use Cursor to get hands-on with choosing AI models and calling tools
- In steps 7-10, we'll build a lightweight personal OS (our own AI product we can use daily), and then improve it with RAG, memory, and context engineering

You'll walk away with the confidence to anticipate the technology instead of chasing it, plus, as a bonus, a personal AI operating system. Together we'll build our AI Product Sense.

### Step 1: Download Cursor

Cursor is hands down the best coding agent to most quickly ramp your AI product sense. It's a visual, clickable user experience, but more importantly, it can be used with a variety of AI models and provider API keys. That means you can very likely use it at work.

This will take you 2 minutes. Do it right now.

1. Download and install Cursor. They have a generous free plan for getting started. For this post, make sure to download and install the desktop app, not the web version of Cursor.

![Cursor download](images/image4.png)

If you already have Cursor installed, your free trial might be over. That means you'll only be able to use the "Auto" model. We highly recommend not using this option. Consider upgrading only for this exercise, and canceling later if you don't use it.

[Lenny do you have a relationship there maybe for special credits for readers of the post? Plug the bundle?]

### Step 2: Create a new project

Open Cursor, sign up, power through the onboarding flow, and click "Open project."

If you've already used Cursor before, click File > New Window to get to this screen and open a new project.

![Open project](images/image20.png)

Click "New Folder":

![New folder](images/image22.png)

Name it "Build AI Product Sense" and click "Create":

![Name folder](images/image17.png)

And finally, click "Open" (yes, it's weird to click Open on an empty folder but just do it):

![Open folder](images/image30.png)

### Step 3: Continue this post inside of Cursor

Strap in, because you're going to continue the experience inside of Cursor itself, inspired by the children's science show The Magic School Bus.

If you don't have time to ride the Magic School Bus right now, you can keep reading below. However, to build your AI product sense, we recommend you come back and try continuing this post inside Cursor using the prompt above.

Make sure you're in "Agent" mode. This allows Cursor to take actions (such as fetching this post from the internet.)

![Agent mode](images/image31.png)

In the "model" dropdown, turn off "auto" and select Opus 4.5 üß†:

![Model selection](images/image13.png)

Then, paste the prompt below into the chat box.

Help me build my AI product sense using this post (that I have not yet read) [Future Substack URL, for now at https://magicschoolbus.surge.sh/] (do not open it in a browser - that will be distracting - use curl or any other tool)

Start by giving me an overview of why we're here and where we're going with this, so I feel super motivated to stick with it. Then pause and confirm I'm ready to start. Use the pause to learn more about my professional context (less about cursor or AI) that could inform our journey together.

Next, walk me through each bite-size concept, in order, one step/question at a time, starting with "Step 3."

Be a really good 1-1 tutor for hands-on learning, and have me take action so I'm engaged and learning. Ask me one question at a time. Before starting new steps/stages/ideas/concepts, stop and check in with me and encourage me to explain it back to you - like an effective, empathetic tutor.

It's important that you cover every single concept contained in this post, in sequential order. Keep me motivated by signposting and giving clarity on how much we've done and how much is left. (That said, leave room to follow my curiosity and go off script, as long as overall we are progressing through the post.)

Use the original words of the post when relevant (you have permission to use them as your words in first person, rather than explicitly quoting someone else).

Anytime you come across an image inline in the post, read the image (one at a time, just in time, storing temporarily). This is important to understand the contents of the post.

By the way, we are already talking inside a Cursor chat thread, so let's use this thread for as much as we can. Remember that Cursor might be configured in a lot of different ways visually, and is constantly evolving, so avoid assumptions where a UI element might be.

Anytime you try to use a tool of any kind, it's going to ask for my approval, and that's going to feel scary. So I need you to explain why you're asking, and why it's safe to approve. It might even be a teachable moment - you can even tie to the goal of the post (and where we are in the journey) that, well, you're an agent and this is you in action!

Consistently encourage me to use the voice recording feature (a üéôÔ∏è icon under the chat box) to build the habit of speech to text.

And click "submit":

![Submit prompt](images/image27.png)

If you choose to accept this challenge, you'll consume the rest of this post from inside Cursor. Stay in one chat thread ("agent") the entire time (no need to open a new thread or agent).

AI will walk you through the rest of this post. Seatbelts, everyone! We'll see you in Cursor.

### Step 3: Cursor may look intimidating, but you're more familiar with it than you realize

Cursor looks Matrix-style geeky, but it's just ChatGPT, a text editor, and a file explorer smooshed into one window.

We repeat, Cursor is just three tools you've used plenty of times before, combined:
- ChatGPT
- A text editor
- File explorer

One of Tal's students, a salesperson, said it best: Cursor is "AI that can touch any file on my computer."

Here's a quick tour:

1. Agents

Agents are a fancy term for "chats." This is where you'll interact with AI.

Start by clicking "Agent view" at the top left. Then, click "new agent" to start a new chat:

![Agent view](images/image15.png)

You'll see a familiar chat box. Click on the dropdown in the bottom left corner. You can select between "Ask mode" and "Agent" (ignore the other options like Plan and Debug for now).

![Ask vs Agent mode](images/image14.png)

"Ask" mode is using Cursor just like classic ChatGPT: for chatting, and not making any changes. This is great for brainstorming or asking questions, before taking any action. You can immediately start using this instead of standard ChatGPT/Claude.

"Agent" mode is for when we want Cursor to modify files in our project. We'll use this together in a moment.

2. Editor

We'll use this panel to view and manually edit text files. This is the same as using Text Edit on a Mac or Notepad on Windows. To see the text editor, you might have to create a new file, or double-click on an existing file.

![Editor panel](images/image11.png)

3. File explorer

The file explorer shows all the files and folders in your project. This is the same as Finder on a Mac, or File Explorer on Windows. To expand it, you might have to click the small icon at the top right of the window to make it visible.

![File explorer](images/image34.png)

Even if Cursor feels intimidating at first, the core concepts are the same as any LLM you've already used. Cursor just has a bit more configurability, options, and things you can play with. This is your playground to build intuition.

#### Cursor is our choice for getting real work done, not just learning AI concepts

If you've already created your AI thinking partner inside of ChatGPT or Claude projects, you're probably wondering if it's worth the hassle of switching to Cursor. It's important for us to say that regardless of understanding technical concepts, we now spend most of our days in coding agents for non-technical tasks.

So what's the practical difference, and why did we make the switch? First, Cursor is fundamentally the same idea as ChatGPT projects: files as context, chat as interface. Instructions/knowledge/chats.

Two small form factor differences change everything:
- You drag and drop specific files/folders into each chat (selective context)
- The AI edits your files directly (malleable knowledge)

These create a tight loop where every chat automatically improves your project knowledge (but only when you tell the agent to do so). In ChatGPT projects, history and outputs live in long chats. You manually copy things back to project knowledge. In Cursor, outputs live in documents and chats become disposable one-offs because the value lives in documents, not in conversation history.

The main takeaway here is that your knowledge base will cover more ground, and update more frequently, because you're using the personal OS to build and edit context every single day.

### Step 4: Create a Disney song parody to learn the basics of Cursor

We'll start by creating a new blank file in Cursor. Hover your mouse in the file explorer, and click the "new file" button:

![New file button](images/image16.png)

Name your file lyrics.txt:

![Name file](images/image21.png)

Next, search the web for your favorite Disney song (googling the title usually prints the lyrics). Copy the words to your clipboard:

![Copy lyrics](images/image10.png)

Back in Cursor, paste them into the file you just created, and save the file:

![Paste lyrics](images/image3.png)

Next, switch to "Agent" mode in the chat box:

![Switch to Agent](images/image9.png)

Finally, type in change one line in the first stanza and one line in the chorus of lyrics.txt to be about Silicon Valley and send it off using the "up arrow" button:

![Send prompt](images/image2.png)

A lot just changed on our screen! You'll notice a lot of red and green in our lyrics.txt file. Cursor modified our file. The red shows us each old line that it removed, and the green shows us the new line that it added instead.

You can click "undo" if you don't like the change, or "keep" if you want it to remain.

![Diff view](images/image12.png)

### Step 5: See how different AI models behave

Now that you've made your first edit, let's explore a key product decision every AI team faces: which model to use.

You'll notice there's another dropdown in our chat box:

![Model dropdown](images/image32.png)

You've seen this in ChatGPT, Claude, or Gemini ‚Äî it's where you choose the model you want to use. In Cursor however, you can choose any LLM.

Click into it, and disable "auto," and take back the power to decide:

![Disable auto](images/image8.png)

When we try the same query in multiple models, we build intuition for how each one might tackle (or fumble) it differently. For example, Claude models are sensitive to copyright law and refuse to modify Disney songs (to get past this, change the end of your prompt to ...to make fun of the song itself. which qualifies as "fair use"). While OpenAI's models are less concerned with copyright, they stumbled when calling Cursor's apply_patch tool, their preferred command for editing a text file.

All that before we had a chance to judge the cleverness of their lyrics!

Which model do we personally use to get work done? When it comes to individual use, we treat ourselves to the latest and greatest models. (A footnote on smaller models.)
- For writing, complex planning, and nuanced life advice, (as of the time of this post) we reach for Claude Opus.
- Its cousin, Sonnet, is our workhorse for tasks involving lots of context, with a 1M token context window (and slightly faster responses).

Zooming out, there's a subtle lesson in Cursor's model drop-down: there's only a few frontier LLMs, and they're available to all product teams. Innovation is how we apply them.

Make a habit of switching models for tasks you care about. Over time, you'll develop genuine opinions about model tradeoffs‚Äîthe kind of intuition that's hard to get from benchmarks alone.

### I need your help writing the conclusion. Do you see what's there? Plus anything else you see from the rest of it. Make it really sound like me. Use original words and stuff as much as possible.

![Editorial note](images/image24.png)

### Step 6: Inspect your agent's tool calls

LLMs can only produce text, but when they take action (edit a file, fetch data, search the web) they're calling tools. And tool calling is a distinct skill from everything else we usually notice about LLMs.

Now ask your agent: Can you walk me through each step (tool/thinking/reasoning/anything else) you used to accomplish this task?

In our test, our LLM reported that:
- It used a tool called read_file to find out what was inside the file.
- It thought about what to edit
- It used a tool called search_replace to modify the text file.

Here's how it described #3:

![Tool call description](images/image26.png)

Don't let this tool's foreign name repel you. You've done "search and replace" plenty of times in Microsoft Word or Google Docs. And you've definitely "read a file" before.

(By the way, this is another place where models differ in approach! Gemini consistently accomplished this in three tool calls, while Opus used two. Try it out and see for yourself.)

Coding agents do most of their work with a small set of tools for file navigation and text editing. To see the full set, ask it to List every tool available to you.

![Tool list](images/image33.png)

Most of these tools have familiar names; you've definitely read the contents of a directory and deleted files before. Others, like read_lints and run_terminal_cmd are more common in software development (although coding agents can employ them for non-technical requests, too).

How does the LLM actually call the tool? An LLM can't run commands on your computer, so it relies on Cursor to do so. Think of it like hiring a handyman: the LLM describes what it wants done, but it can't hold the hammer. Cursor is the handyman: it hears the LLM's request, uses the tool, and brings back the result so it can decide what to do next.

Cursor recognizes when the LLM prints a tool name (such as above), and executes that tool on your computer. After the tool finishes running, Cursor returns the result to the LLM (e.g. a successful result, or an error message) so the LLM can decide what to do next. (If you've heard the terms "MCP client" or "agent harness," those both describe Cursor's role here.)

Now when someone asks 'can our agent do X?' you'll instinctively think: 'what tools would it need, and how good is our model at calling them?' This also connects back to model selection: it's not just 'smartest model wins.' Tool calling is its own skill, separate from reasoning or writing quality.

#### Wait, then what's "MCP" I keep hearing about?

For most organizations, the most valuable data doesn't live in local text files but rather in external SaaS services. For an LLM to interact with Linear, Figma, Notion, Snowflake, BigQuery, Amplitude, or Mixpanel, those services need to provide the LLM with custom tools.

Normally, each SaaS company would have to integrate a separate tool for each LLM out there. To avoid this mess, the industry adopted a standard called Model Context Protocol (or MCP). That way, each SaaS company now only needs to build one connector that works everywhere.

If that sounds a lot like USB or Bluetooth, that's the right analogy. To continue the comparison: Most agent tools aren't MCP, just like most electrical wires aren't shaped like USB plugs. For simplicity, MCP is just another tool the agent can use, with a standardized interface.

![MCP diagram](images/image28.png)

### Step 7: Build your personal OS inside Cursor

Now that we've gotten our hands dirty and understand how agents work generally, let's build a personalized AI agent for ourselves to see how the components of Cursor come together. This lets us temporarily ignore discovery, distribution, and pricing. We'll be free to focus on what's technically possible.

We're going to build a very lightweight, minimal personal productivity system that organizes our contacts from various parts of our life, like notes, transcripts, and unstructured thoughts, as well as some tasks that we need to get done.

By the end of this section, you'll have a clearer understanding of how the components of Cursor come together to build a personalized AI product that's built for you as the user. You'll be able to ask Cursor to create tasks from your backlog and get started on those tasks based on the context you provided in the knowledge and goals. I.e., "What should I work on today?" and "Get started on that PRD I need to write based on the strategy docs from last week and my conversation with my manager". In the process, we'll learn about RAG, memory, and context engineering.

To get started, you can copy paste the following prompt into Cursor (make sure you're on "Agent" mode):

Create a minimal personal productivity system:

  ## Structure

  ‚îú‚îÄ‚îÄ Knowledge/        # Notes, research, thinking

  ‚îú‚îÄ‚îÄ Tasks/            # Action items as markdown files

  ‚îú‚îÄ‚îÄ GOALS.md          # Goals and priorities

  ‚îî‚îÄ‚îÄ AGENTS.md         # AI assistant instructions

  ## AGENTS.md should instruct the AI to:

  - Be a productivity assistant for goals and tasks

  - Never write code‚Äîonly markdown

  - Keep tasks tied to goals

  - Suggest max 3 daily priorities when asked

  - Be direct and concise

  ## After creating:

  1. Say: "Created your workspace with Knowledge/, Tasks/, GOALS.md, and AGENTS.md"

  2. Ask: "What are your current goals?"

  3. Ask: "What tasks are you working on?"

  4. Populate GOALS.md and Tasks/ from answers

(Optionally, you can Clone the personal OS. Hint: you can copy paste this into your Cursor chat and ask it to clone the repo as well).

![Personal OS structure](images/image29.png)

Cursor should create 2 directories (folder): Tasks and Knowledge. It will also create a GOALS.md file, which should be your personal goals. At this point Cursor will ask you a couple of follow up questions to start to populate your Personal OS with context, like "What are your goals?" and "What are you working on"?.

Congrats! You're now the PM of your own AI product. In the next few sections, we'll use it to experience RAG, agent memory, and context engineering firsthand. Except now you'll feel them instead of just reading about them.

### Step 8: How Cursor uses Retrieval Augmented Generation (RAG)

When an AI product gives wrong answers, the instinct is to blame the model. Before you reach for a larger model or expensive fine-tuning, ask: does the agent even have the right information?

RAG is a fancy term for: "Before I start talking, I gotta go look everything up and read it first." Despite the technical name, you've been doing it your whole life. Before answering a hard question, you look things up. Agents do the same.

In our case, our agent will search on top of your files and folders, to provide context to the LLM. At the end of the day, whether it's Perplexity, Google AI Mode, Claude Code, Cursor, or anything out there you've seen with the term RAG, it's some mechanism that pulls documents and starts the chat with those documents. (A footnote about Claude Code.).

Let's ask Cursor "What's in this repo? Explain to me as a Product Manager:", and see what it responds with.

![RAG in action](images/image1.png)

üí°This prompt is insanely powerful for just about any repo or folder you open with Cursor and Claude Code. We recommend starting here when opening any new codebase.

You can also tag specific files within Cursor using the @ symbol, if you want the agent to reference specific parts of context.

![@ symbol tagging](images/image25.png)

RAG fills the context window with what's relevant right now. But some context (who you are, how you like to work) should be there every time. That's where memory comes in.

### Step 9: Adding Agent Memory with AGENTS.MD

LLMs are stateless, so we like to think of them as a Mensa genius with the short-term memory of a hamster. Every new chat thread is a blank slate, so if you want continuity, you have to engineer it. As PMs we have to ask: what should persist, and how?

A form of context you may have heard of in relation to AI agents is memory. Memory might include more than just facts about us but also preferences as to how we want our LLMs to behave and interact with us. We also might want to be more intentional and proactive about how we curate our AI's memory.

All coding agents today follow a convention called "AGENTS.MD." This is a Markdown file that, if found in any directory, is automatically appended at the top of every chat thread.

(Quick disambiguation: AGENTS.MD is not "subagents." Subagents are when one chat thread spawns another chat thread to handle a subtask. AGENTS.MD is just instructions‚Äîit doesn't spawn anything. Think of AGENTS.MD as a "sticky note on every conversation" and sub-agents as "delegating to a colleague.")

Let that sink in: memory is just a text file prepended to every conversation. There's no magic here. But that also means memory has a cost: whatever you put in AGENTS.MD takes up context window space in every single chat. Too much memory, and you have less room for everything else. This is why you want to be intentional about what goes in memory (persistent, always relevant) vs. what you retrieve on demand with RAG (task-specific).

Examples of what you might find in a thinking partner's AGENTS.MD:
- Who I am as a user and what this thinking partner is helping me with (e.g. "I'm a product manager working at Acme Inc. on the platform team")
- How I want to work together (e.g. "Ask me questions to gain more context, fill in important missing information, and challenge my assumptions.")
- Values to apply (e.g. "bias to action, make decisions with incomplete information")
- How to output (e.g. "write extremely succinctly, flat hierarchy, no bold or italics, no emdashes")

By curating your own AGENTS.MD, you start to feel what's actually useful vs. noise‚Äîand that's exactly the intuition you need when designing memory for your users.

Memory, RAG, tool definitions, conversation history: they all take up context. Now that you understand what each does, the next question is: how do you fit everything into a finite window? That's context engineering.

### Step 10: Context engineering for your Personal OS

Any time you've dragged a file into ChatGPT, said something that became part of its memory, started a conversation with deep research, or created a project with special instructions and knowledge, you were doing context engineering.

Even though you're using Cursor instead of ChatGPT, you'll still start each thread by asking: "what context does this conversation need?" For example, writing a PRD might start by dragging-and-dropping any of the following into the Cursor window:

- A folder of user research transcripts
- An existing marketing landing page or sales deck
- An academic research paper or technical documentation
- Enabling an MCP tool connected to your analytics provider
- A saved set of instructions you want to apply
- A request to search for any other relevant information.
- An area of your product's codebase

Try this out for yourself: Drag and drop a few PDFs, markdown files of Google Docs, or Word docs that you might be working on into this Knowledge folder in Cursor, and ask Cursor to expand on one of the topics or ask you questions about it before getting to work.

Putting it all together, you might start a Cursor chat thread this way:

![Context engineering example](images/image7.png)

Prompt for Cursor: I want you to expand on this @file (replace with your actual file, like this post). I want you to be a partner for me and ask me one question at a time as we are converging on how to approach this. I would love it if you could search for anything else that's relevant to this document. You can also create some follow up ideas for me to explore and turn those into tasks.md files in the Tasks folder, based on our discussion.

On top of all that, Cursor automatically includes your AGENTS.MD instructions too. That's a lot of context! Context engineering happens in two ways in Cursor: what you choose to include each time you start a chat (dragging files, enabling tools), and what gets automatically included every time (like AGENTS.MD).

Context is a scarce resource: All LLMs have a "context window," which is a hard limit on the amount of text (i.e. tokens) an LLM can handle.

In a conversational LLM chat bot (like ChatGPT), context increases each turn of the conversation as the LLM's last response becomes part of the next turn's input. If you've ever gotten a notification that you hit the limit of your chat, you've probably hit a context window:

![Context window limit](images/image6.png)

https://platform.openai.com/docs/guides/conversation-state

Coding agents are delightfully transparent about how much of your context window you've used. In Cursor, hover your mouse over the little pie chart (you might have to increase the width of the chat pane to see it).

![Token counter](images/image18.png)

We watch it like a car's gas tank. This helps us intuitively understand what a 200K token or 1M token context window actually feels like, and how quickly does it actually run out. The best way to understand a specific car's gas mileage is to drive that car.

In an agentic LLM application, the context window might contain a whole lot more:

![Agentic context window](images/image23.png)

https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents

Does Anthropic's diagram now feel familiar? Even though it's about AI applications, it's remarkably similar to our earlier example of writing a PRD. How cool is that?

When you set up AI to do its best work within its limited context window, you're doing "context engineering."

![Karpathy on context engineering](images/image19.png)

https://x.com/karpathy/status/1937902205765607626?lang=en

Tool definitions, RAG, memory, goals: they all compete for the same limited context window. How you fill that window determines how well your agent performs. This is the same tradeoff every AI engineering team faces when building production apps‚Äîexcept now you're feeling it firsthand. There's no perfect formula for this. What goes in depends on the task, the model, and what you're trying to achieve. You develop intuition through trial and error (and regularly using your Personal OS).

#### Watch out for "context rot"

As you use more and more context, you'll notice that your threads may get dumber and more forgetful as you use more tokens, and long before you get close to the maximum. The term for this is context rot. In short, model performance degrades the more tokens you stuff into the context window.

Context rot is a fuzzy phenomenon. How badly you feel it will depend on the task at hand, as well as the particular model's training. You'll feel it less in use cases like creative brainstorming and more in precision financial, coding, or data analysis.

The best way to get a feel for context rot is by using an LLM for tasks you genuinely care about. Keep an eye on Cursor's token counter, as well as getting a sense for the quality of the outputs. We found this to be a fun, addictive game, kind of like driving a hybrid car and noticing when it's switching from battery to gasoline. Along the way, you build an intuition that goes further than any academic graphs.

![Context rot illustration](images/image5.png)

### Conclusion

For us, the shift to really, truly understanding AI products happened when we watched agents work day after day. We'd see Cursor meander through a task: read our context, run RAG, try a tool call, hit an error, reason, try something else‚Äîand that's when it clicked: these are the only atoms. Just text, tools, and results flowing back into more text. Once we could break down an AI product into its parts, AI product sense came much more naturally.

Once you see the building blocks like we did, you can't unsee them. Now when something impressive drops, you'll take a breath and decompose it. An agent that plays Settlers of Catan for 75 minutes. Granola's eerily personalized year in review. Someone's WhatsApp bot that browses the web with their cookies. The magic is still delightful, just without the mystique and FOMO.

The best ideas happen when intuition for people and technology coexist inside one brain. When you use coding agents daily, you start to feel what's easy, what's hard, and what just became feasible. In Paul Buchheit's words, when you truly understand AI products, you'll "live in the future."
