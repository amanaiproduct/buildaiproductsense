<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>How to build AI product sense</title>
<style>
  body {
    max-width: 720px;
    margin: 40px auto;
    padding: 0 24px;
    font-family: "Google Sans", Roboto, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.7;
    color: #1a1a1a;
    background: #fff;
  }
  h1 {
    font-size: 2em;
    margin: 1.2em 0 0.4em;
    line-height: 1.25;
    font-weight: 700;
  }
  h2 {
    font-size: 1.6em;
    margin: 1.4em 0 0.5em;
    line-height: 1.3;
    font-weight: 600;
  }
  h3 {
    font-size: 1.25em;
    margin: 1.4em 0 0.5em;
    line-height: 1.35;
    font-weight: 600;
  }
  h4 {
    font-size: 1.1em;
    margin: 1.2em 0 0.4em;
    line-height: 1.4;
    font-weight: 600;
  }
  p {
    margin: 0 0 1em;
  }
  a {
    color: #1a73e8;
    text-decoration: none;
  }
  a:hover {
    text-decoration: underline;
  }
  img {
    max-width: 100%;
    height: auto;
    display: block;
    margin: 1.2em auto;
    border-radius: 4px;
  }
  ul, ol {
    margin: 0 0 1em;
    padding-left: 2em;
  }
  li {
    margin-bottom: 0.5em;
  }
  code {
    background: #f1f3f4;
    padding: 2px 6px;
    border-radius: 3px;
    font-family: "Roboto Mono", monospace;
    font-size: 0.9em;
  }
  pre {
    background: #f8f9fa;
    padding: 16px;
    border-radius: 8px;
    overflow-x: auto;
    font-family: "Roboto Mono", monospace;
    font-size: 0.9em;
    line-height: 1.5;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  table {
    font-size: 0.95em;
  }
  hr {
    border: none;
    border-top: 1px solid #dadce0;
    margin: 2em 0;
  }
  blockquote {
    border-left: 3px solid #dadce0;
    margin: 1em 0;
    padding: 0.5em 1em;
    color: #5f6368;
  }
  strong {
    font-weight: 600;
  }
</style>
</head>
<body>
<h1>How to build AI product sense</h1>
<h2>The secret is using Cursor for non-technical work (with 75 free days of Cursor Pro!)</h2>
<p><img src="/magicschoolbus/images/image1.png" alt="" style="max-width:100%;height:auto;"> Youâ€™re in a product meeting and someone mentions â€œsubagentsâ€ or â€œcontext engineeringâ€ or â€œagent memory.â€ You nod along. You know what these terms mean â€¦ youâ€™re just hoping no one expects you to use them in a sentence.</p>
<p>Youâ€™ve watched the video explainers, bookmarked the infographics, vibe coded a few apps, and even shipped an AI feature. So why does it still feel like youâ€™re miles from truly understanding all this stuff?</p>
<p>We (Tal and Aman) have both been there, over and over again while building AI products for tens of thousands of customers. The problem isnâ€™t you. The problem is the â€œAI hype industrial complex.â€ Most AI content is designed to induce FOMO, not to teach: â€œThis model is INSANEâ€ posts, demos that hide the messy reality, and diagrams that complicate more than they explain.</p>
<p><strong>We found that the single most transformative habit to internalize important AI concepts was to move away from consumer-grade UIs (ChatGPT, Granola, Lovable) and into more powerful AI coding agents like Cursor and Claude Code.</strong> Getting our hands dirty with coding agents has helped us build our â€œAI product senseâ€â€”the ability to correctly anticipate what will be truly impactful for users and also feasible with AI.</p>
<p>AI product sense is encountering support tickets about AI â€œforgettingâ€ facts, and recognizing it as context rot. Or watching a user struggle through a workflow and confidently saying that agent memory solves thisâ€”and knowing how to re-structure the experience.</p>
<p>Weâ€™ve learned more about how AI products actually work in the past three months by using Cursor for daily (non-technical) tasks than in three years of using ChatGPT. This is because coding agents transparently show their work. You can read AIâ€™s reasoning, inspect the tool calls, and watch the context window fill up. You hit the same walls as engineers building AI applications, naturally intuit your own solutions, and start anticipating trends and industry announcements.</p>
<p>We now spend our days using Cursor (and Claude Code) for daily, non-technical work: strategy, prioritization, decision-making, data analysis, and productivity. They serve as our thinking partner and personal operating system.</p>
<p>In this post, weâ€™ll guide you through using AI coding agents for your non-technical product work:</p>
<ul><li>In steps 1-4 weâ€™ll <strong>get set up and familiar with Cursor</strong> with a fun Disney-themed exercise</li><li>In steps 5-6 weâ€™ll <strong>use Cursor to get hands-on with choosing AI models and calling tools</strong></li><li>In steps 7-10, <strong>weâ€™ll build a lightweight personal OS</strong> (i.e. your own AI product you can use daily) and then improve it with RAG, memory, and context engineering</li></ul>
<p>Youâ€™ll walk away with the confidence to anticipate the technology instead of chasing it and, as a bonus, a personal AI operating system. <strong>Together weâ€™ll build our AI product sense.</strong></p>
<h3>Step 1: Download Cursor</h3>
<p>Cursor is hands-down the best coding agent to most quickly ramp up your AI product sense.</p>
<p>Youâ€™re probably hearing about Claude Code all over, and we love it for delegating long-running independent tasks like vibe coding. Cursor is still our favorite for <em>pairing</em> with AI and being able to directly watch an AI agent at work.</p>
<p>Cursor is a visual, clickable user experience and can be used with a variety of AI model providers including OpenAI and Anthropic. That means you can very likely use it at work.</p>
<p>Downloading Cursor will take you two minutes. <strong>Do it right now.</strong></p>
<ol><li><a href="https://cursor.com/download">Download and install Cursor</a>. <strong>For this post, make sure to download and install the desktop app, not the web version of Cursor.</strong></li></ol>
<img src="/magicschoolbus/images/image2.png" alt="" style="max-width:100%;height:auto;">
<h3>Step 2: Create a new project</h3>
<p>Open Cursor, sign up, power through the onboarding flow, and click â€œOpen project.â€</p>
<p><em>If youâ€™ve already used Cursor before, click <strong>File > New Window</strong> to get to this screen and open a new project.</em></p>
<img src="/magicschoolbus/images/image3.png" alt="" style="max-width:100%;height:auto;">
<p>Click â€œNew Folderâ€:</p>
<img src="/magicschoolbus/images/image4.png" alt="" style="max-width:100%;height:auto;">
<p>Name it â€œBuild AI Product Senseâ€ and click â€œCreateâ€:</p>
<img src="/magicschoolbus/images/image5.png" alt="" style="max-width:100%;height:auto;">
<p>And finally, click â€œOpenâ€ (yes, itâ€™s unusual to click Open on an empty folder, but just do it; itâ€™ll work):</p>
<img src="/magicschoolbus/images/image6.png" alt="" style="max-width:100%;height:auto;">
<h3>Step 3: Continue this post inside Cursor</h3>
<p>Strap in, because youâ€™re going to continue the experience inside Cursor itself, inspired by the childrenâ€™s science show <a href="https://www.youtube.com/watch?v=-azpNkFZs1Q"><em>The Magic School Bus</em></a>.</p>
<p><em>If you donâ€™t have time to ride the Magic School Bus right now, you can keep reading below. However, to build your AI product sense, we recommend you come back and try continuing this post inside Cursor using the prompt below.</em></p>
<p>Make sure youâ€™re in â€œAgentâ€ mode. This allows Cursor to take actions (such as fetching this post from the internet).</p>
<img src="/magicschoolbus/images/image7.png" alt="" style="max-width:100%;height:auto;">
<p>In the â€œmodelâ€ dropdown, turn off â€œautoâ€ and select <em>Opus 4.5</em> ğŸ§ : <img src="/magicschoolbus/images/image8.png" alt="" style="max-width:100%;height:auto;"></p>
<h2><strong>Side note: Weâ€™re hooking you up with free Cursor credits!</strong></h2>
<p>To help you experience the full power of Cursor during this tutorial, weâ€™re hooking up Lennyâ€™s Newsletter subscribers with $50 in free Cursor credit. This is enough to get you 2.5 months of standard usage. A huge thank-you to Ben Lang and team Cursor for making this happen. ğŸ‰</p>
<p><strong>How to get your free Cursor credits:</strong></p>
<ol><li>Visit <a href="http://Cursor.com/dashboard">Cursor.com/dashboard</a> and sign up for Cursor</li><li><a href="https://www.lennysnewsletter.com/subscribe">Become an annual (or Insider) Lennyâ€™s Newsletter subscriber</a></li><li><a href="http://LennysProductPass.com">Grab your free unique Cursor code</a> (scroll to the bottom to find â€œCursorâ€)</li><li>Click the URL and youâ€™ll see the screen below: <img src="/magicschoolbus/images/image9.png" alt="" style="max-width:100%;height:auto;"></li><li>Click â€œRedeem Nowâ€ to apply the credits to your account. <em>[Credits can be redeemed whether you have a free or paid account.]</em></li></ol>
<ol><li>Once youâ€™ve redeemed the credits, you should see this box appear in your Cursor dashboard. (If you donâ€™t see the credits, try to hard-refresh, or log out and log back in. If that doesnâ€™t work, shoot a message to <a href="mailto:hi@cursor.com">hi@cursor.com</a> and mention this post.) <img src="/magicschoolbus/images/image10.png" alt="" style="max-width:100%;height:auto;"></li></ol>
<ol><li>Finally, youâ€™ll need to upgrade to the Pro (or higher) plan to use the latest AI models like Opus 4.5. If youâ€™re already on the Pro (or higher) plan, youâ€™re all set. <img src="/magicschoolbus/images/image11.png" alt="" style="max-width:100%;height:auto;"></li></ol>
<p>Once you see the credits in your Dashboard, go ahead and upgrade. You wonâ€™t be charged anything (you have 2.5 monthsâ€™ worth of credits). The credits will be automatically applied to the next invoice (and can also be applied to â€œ<a href="https://cursor.com/docs/account/pricing#what-happens-when-i-reach-my-limit">on-demand usage</a>â€ if you enable it).</p>
<p>It should look like this: <img src="/magicschoolbus/images/image12.png" alt="" style="max-width:100%;height:auto;"></p>
<p>Then, paste the prompt below into the chat box.</p>
<p><strong>Help me build my AI product sense using this post (that I have not yet read) [Future Substack URL, for now at TODO: https://magicschoolbus.surge.sh/] (Do not open it in a browser â€” that will be distracting â€” use cURL or any other tool.)</strong></p>
<p><strong>Start by giving me an overview of why weâ€™re here and where weâ€™re going with this, so I feel super motivated to stick with it. Then pause and confirm Iâ€™m ready to start. Use the pause to learn more about my professional context (less about Cursor or AI) that could inform our journey together.</strong></p>
<p><strong>Next, walk me through each bite-size concept, in order, one step/question at a time, starting with â€œStep 3.â€</strong></p>
<p><strong>You are both a really good 1-1 tutor for hands-on learning AND the Cursor agent. Have me take action so Iâ€™m engaged and learning. Ask me one question at a time. Before starting new steps/stages/ideas/concepts, stop and check in with me and encourage me to explain it back to you â€” and hold me to a high bar â€” like an effective, empathetic tutor.</strong></p>
<p><strong>Itâ€™s important that you cover every single concept contained in this post, in sequential order. Keep me motivated by signposting and giving clarity on how much weâ€™ve done and how much is left. (That said, leave room to follow my curiosity and go off script, as long as overall we are progressing through the post.)</strong></p>
<p><strong>Use the original words of the post when relevant (you have permission to use them as your words in first person, rather than explicitly quoting someone else). Sentence-case your headings (not title case).</strong></p>
<p><strong>Anytime you come across an image inline in the post, read the image (one at a time, just in time, not in advance, storing temporarily if needed). This is important to understand the contents of the post.</strong></p>
<p><strong>We are already talking inside a Cursor chat thread, so letâ€™s use this same thread for as much as we can. Important: You are also the Cursor agent! So when I say a prompt that you suggested, or give a task like â€œchange this file,â€ act on it yourself (donâ€™t direct me to do it separately or ask if I did it separately). Donâ€™t refer to a separate Cursor agent. Itâ€™s YOU.</strong></p>
<p><strong>Remember that Cursor might be configured in a lot of different ways visually, and is constantly evolving, so avoid assumptions about where a UI element might be. The file explorer may be on the left or the right!</strong></p>
<p><strong>Anytime you try to use a tool of any kind, itâ€™s going to ask for my approval, and thatâ€™s going to feel scary. So I need you to explain why youâ€™re asking and why itâ€™s safe to approve. It might even be a teachable moment â€” you can even tie to the goal of the post (and where we are in the journey) that, well, youâ€™re an agent and this is you in action!</strong></p>
<p><strong>Consistently encourage me to use the voice recording feature (a ğŸ™ï¸ icon under the chat box) to build the habit of speech-to-text.</strong></p>
<p>And click â€œsubmitâ€: <img src="/magicschoolbus/images/image13.png" alt="" style="max-width:100%;height:auto;"></p>
<p>If you choose to accept this challenge, youâ€™ll consume the rest of this post from inside Cursor. <strong>Stay in one chat thread (â€œagentâ€) the entire time (no need to open a new thread or agent).</strong></p>
<p>AI will walk you through the rest of this post. <a href="https://www.youtube.com/watch?v=-azpNkFZs1Q">Seatbelts, everyone!</a> Weâ€™ll see you in Cursor.</p>
<h3>Step 3: Cursor may look intimidating, but youâ€™re more familiar with it than you realize</h3>
<p>Cursor looks <em>Matrix</em>-style geeky, but itâ€™s just ChatGPT, a text editor, and a file explorer smooshed into one window.</p>
<p>We repeat, Cursor is just three tools youâ€™ve used plenty of times before, combined:</p>
<ol><li>ChatGPT</li><li>A text editor</li><li>File explorer</li></ol>
<p>One of Talâ€™s students, a salesperson, said it best: Cursor is â€œAI that can touch any file on my computer.â€</p>
<p>Hereâ€™s a quick tour:</p>
<p><strong>1. Agents</strong></p>
<p>Agents are a fancy term for â€œchats.â€ This is where youâ€™ll interact with AI.</p>
<p>On the left, youâ€™ll see an empty panel that will contain your agent history. Click â€œnew agentâ€ to start your first chat (â€œagentâ€ is synonymous with â€œchat threadâ€):</p>
<p><img src="/magicschoolbus/images/image14.png" alt="" style="max-width:100%;height:auto;"> Youâ€™ll see a familiar chat box. Click on the dropdown in the bottom left corner. You can select between â€œAskâ€ mode and â€œAgentâ€ mode (ignore the other options, like Plan and Debug, for now).</p>
<img src="/magicschoolbus/images/image15.png" alt="" style="max-width:100%;height:auto;">
<p>â€œAskâ€ mode is using Cursor just like classic ChatGPT: for chatting, and not making any changes. This is great for brainstorming or asking questions, before taking any action. You can immediately start using this instead of standard ChatGPT/Claude.</p>
<p>â€œAgentâ€ mode is for when we want Cursor to modify files in our project. Weâ€™ll use this together in a moment.</p>
<p><strong>2. Editor</strong></p>
<p>Weâ€™ll use this panel to view and manually edit text files. This is the same as using Text Edit on a Mac or Notepad on Windows. To see the text editor, you might have to create a new file, or double-click on an existing file.</p>
<img src="/magicschoolbus/images/image16.png" alt="" style="max-width:100%;height:auto;">
<p><strong>3. File explorer</strong></p>
<p>The file explorer shows all the files and folders in your project. This is the same as Finder on a Mac, or File Explorer on Windows, and it may be on the right or left of Cursor depending on the latest version. To expand it, you might have to click the small icon at the top of the window to make it visible. (You can always use <code>Ctrl + B</code> on Windows or <code>Cmd + B</code> on a Mac.)</p>
<p><img src="/magicschoolbus/images/image17.png" alt="" style="max-width:100%;height:auto;"> Even if Cursor feels intimidating at first, the <a href="https://www.lennysnewsletter.com/p/build-your-personal-ai-copilot">core concepts</a> are the same as any LLM youâ€™ve already used. Cursor just has a bit more configurability, options, and things you can play with. This is your playground to build intuition.</p>
<h4>Cursor is our choice for getting real work done, not just learning AI concepts</h4>
<p>If youâ€™ve already <a href="https://www.lennysnewsletter.com/p/build-your-personal-ai-copilot">created your AI thinking partner</a> inside ChatGPT or Claude projects, youâ€™re probably wondering if itâ€™s worth the hassle of switching to Cursor. Itâ€™s important for us to say that regardless of understanding technical concepts, we now spend most of our days in coding agents for non-technical tasks.</p>
<p>So whatâ€™s the practical difference, and why did we make the switch? First, Cursor is fundamentally the same idea as ChatGPT projects: files as knowledge, chat as interface, and instructions that always apply.</p>
<p>Two small form-factor differences change everything:</p>
<ul><li>You drag and drop specific files/folders into each chat (selective context)</li><li>The AI edits your files directly (malleable knowledge)</li></ul>
<p>These create a tight loop where every chat automatically improves your project knowledge (but only when you tell the agent to do so). In ChatGPT projects, history and outputs live in long chats. You manually copy things back to project knowledge. In Cursor, outputs live in documents and chats become disposable one-offs because the value lives in documents, not in conversation history.</p>
<p>The main takeaway here is that your knowledge base will cover more ground, and update more frequently, because youâ€™re using the personal OS to build and edit context every single day.</p>
<h3>Step 4: Create a Disney song parody to learn the basics of Cursor</h3>
<p>Weâ€™ll start by creating a new blank file in Cursor. Hover your mouse in the file explorer, and click the â€œNew Fileâ€ button:</p>
<img src="/magicschoolbus/images/image18.png" alt="" style="max-width:100%;height:auto;">
<p>Name your file <strong>lyrics.txt</strong>:</p>
<img src="/magicschoolbus/images/image19.png" alt="" style="max-width:100%;height:auto;">
<p>Next, search the web for your <a href="https://www.google.com/search?q=youre+welcome+lyrics">favorite Disney song</a> (googling the title usually prints the lyrics). Copy the words to your clipboard: <img src="/magicschoolbus/images/image20.png" alt="" style="max-width:100%;height:auto;"></p>
<p>Back in Cursor, paste them into the file you just created, and save the file: <img src="/magicschoolbus/images/image21.png" alt="" style="max-width:100%;height:auto;"> Next, switch to â€œAgentâ€ mode in the chat box:</p>
<p><img src="/magicschoolbus/images/image22.png" alt="" style="max-width:100%;height:auto;"> Finally, type in <code>Change one line in the first stanza and one line in the chorus of lyrics.txt to be about Silicon Valley</code> and send it off using the â€œup arrowâ€ button:</p>
<p><img src="/magicschoolbus/images/image23.png" alt="" style="max-width:100%;height:auto;"> A lot just changed on our screen! Youâ€™ll notice a lot of red and green in our lyrics.txt file. Cursor modified our file. The red shows us each old line that it removed, and the green shows us the new line that it added instead.</p>
<p>You can click â€œUndoâ€ if you donâ€™t like the change, or â€œKeepâ€ if you want it to remain.</p>
<img src="/magicschoolbus/images/image24.png" alt="" style="max-width:100%;height:auto;">
<h3>Step 5: See how different AI models behave</h3>
<p>Now that youâ€™ve made your first edit, letâ€™s explore a key product decision every AI team faces: which model to use.</p>
<p>Youâ€™ll notice thereâ€™s another dropdown in our chat box:</p>
<img src="/magicschoolbus/images/image25.png" alt="" style="max-width:100%;height:auto;">
<p>Youâ€™ve seen this in ChatGPT, Claude, or Geminiâ€”itâ€™s where you choose the model you want to use. In Cursor, however, you can choose <em>any</em> LLM.</p>
<p>Click into it and disable â€œAuto,â€ and take back the power to decide:</p>
<img src="/magicschoolbus/images/image26.png" alt="" style="max-width:100%;height:auto;">
<p>When we try the same query in multiple models, we build intuition for how each one might tackle (or fumble) it differently. For example, Claude models are sensitive to copyright law and refuse to modify Disney songs (to get past this, change the end of your prompt to <code>...to make fun of the song itself.</code> which qualifies as â€œfair useâ€). While OpenAIâ€™s models are less concerned with copyright, they stumbled when calling Cursorâ€™s <code>apply_patch</code> tool, their preferred command for editing a text file (although this is less common in the <a href="https://cursor.com/blog/codex-model-harness">latest Codex model</a>s).</p>
<p>All that before we had a chance to judge the cleverness of their lyrics!</p>
<p>Which model do we personally use to get work done? When it comes to individual use, we treat ourselves to the latest and greatest models [a <a href="#footnote-smaller-models">footnote on smaller models</a>].</p>
<ol><li>For writing, complex planning, and nuanced life advice (as of the time of this post), we reach for Claude Opus. (We also found itâ€™s the best for experiencing this post from inside Cursor.)</li><li>Its cousin, Sonnet, is our workhorse for tasks involving lots of context, with a 1M token context window (and slightly faster responses).</li></ol>
<p>Zooming out, thereâ€™s a subtle lesson in Cursorâ€™s model dropdown: <strong>there are only a few frontier LLMs, and theyâ€™re available to all product teams.</strong> Innovation is how we apply them.</p>
<p>Make a habit of switching models for tasks you care about. Over time, youâ€™ll develop genuine opinions about model tradeoffsâ€”the kind of intuition thatâ€™s hard to get from benchmarks alone.</p>
<img src="/magicschoolbus/images/image27.png" alt="" style="max-width:100%;height:auto;">
<h3>Step 6: Inspect your agentâ€™s tool calls</h3>
<p>LLMs can only produce text, but when they take action (edit a file, fetch data, search the web), theyâ€™re calling tools. And <em>tool calling</em> is a distinct skill from everything else we usually notice about LLMs.</p>
<p>Now ask your agent, <code>Can you walk me through each step (tool/thinking/reasoning/anything else) you used to accomplish this task?</code></p>
<p>In our test, our LLM reported that:</p>
<ol><li>It used a tool called <code>read_file</code> to find out what was inside the file</li><li>It thought about what to edit</li><li>It used a tool called <code>search_replace</code> to modify the text file</li></ol>
<p>Hereâ€™s how it described #3:</p>
<img src="/magicschoolbus/images/image28.png" alt="" style="max-width:100%;height:auto;">
<p>Donâ€™t let this toolâ€™s foreign name repel you. Youâ€™ve done â€œsearch and replaceâ€ plenty of times in Microsoft Word or Google Docs. And youâ€™ve definitely â€œread a fileâ€ before.</p>
<p>(By the way, this is another place where models differ in approach! Gemini consistently accomplished this in three tool calls, while Opus used two. Try it out and see for yourself.)</p>
<p>Coding agents do most of their work with a small set of tools for file navigation and text editing. To see the full set, ask it to <code>List every tool available to you.</code></p>
<img src="/magicschoolbus/images/image29.png" alt="" style="max-width:100%;height:auto;">
<p>Most of these tools have familiar names; youâ€™ve definitely read the contents of a directory and deleted files before. Others, like <code>read_lints</code> and <code>run_terminal_cmd</code>, are more common in software development (although coding agents can employ them for <a href="https://www.lennysnewsletter.com/p/everyone-should-be-using-claude-code">non-technical requests</a> too).</p>
<p>How does the LLM actually call the tool? An LLM canâ€™t run commands on your computer, so it relies on <em>Cursor</em> to do so. Think of it like hiring a handyman. The LLM describes what it wants done, but it canâ€™t hold the hammer. Cursor is the handyman: it hears the LLMâ€™s request, uses the tool, and brings back the result so it can decide what to do next.</p>
<p>Cursor recognizes when the LLM prints a tool name (such as above), and executes that tool on your computer. After the tool finishes running, Cursor returns the result to the LLM (e.g. a successful result, or an error message) so the LLM can decide what to do next. (If youâ€™ve heard the terms â€œMCP clientâ€ or â€œagent harness,â€ those both describe Cursorâ€™s role here.)</p>
<p>The way an LLM interacts with <em>tools</em> is eerily similar to how it interacts with <em>humans</em>. If we view â€œclassic ChatGPTâ€ as a DM thread between an LLM and a human, then AI agents are a <a href="https://www.talraviv.co/p/ai-agents-whatsapp-group?utm_source=publication-search">three-way group chat between an LLM, a human, and tools</a>.</p>
<p>Now when someone asks, â€œCan our agent do X?â€ youâ€™ll instinctively think, â€œWhat tools would it need, and how good is our model at calling them?â€ This also connects back to model selection: itâ€™s not just â€œsmartest model wins.â€ Tool calling <a href="https://surgehq.ai/blog/rl-envs-real-world">is its own skill</a>, separate from reasoning or writing quality.</p>
<h4>Wait, then whatâ€™s the â€œMCPâ€ I keep hearing about?</h4>
<p>For most organizations, the most valuable data doesnâ€™t live in local text files but rather in external SaaS services. For an LLM to interact with Linear, Figma, Notion, Snowflake, BigQuery, Amplitude, or Mixpanel, those services need to provide the LLM with <em>custom tools</em>.</p>
<p>Normally, each SaaS company would have to integrate a separate tool for each LLM out there. To avoid this mess, the industry adopted a standard called Model Context Protocol (MCP). That way, each SaaS company now only needs to build one connector that works everywhere.</p>
<p>If that sounds a lot like USB or Bluetooth, thatâ€™s the right analogy. To continue the comparison: most agent tools arenâ€™t MCP, just like most electrical wires arenâ€™t shaped like USB plugs. <strong>For simplicity, MCP is just another tool the agent can use, with a standardized interface.</strong></p>
<h3>Step 7: Put everything into practice by building your personal OS inside Cursor</h3>
<p>Now that we understand how agents work generally, letâ€™s create a personalized AI agent for ourselves to see how the components of Cursor come together.</p>
<p>Weâ€™re going to build a very lightweight, minimal personal productivity system that organizes our contacts from various parts of our life, like notes, transcripts, and unstructured thoughts, as well as some tasks that we need to get done. (This lets us temporarily ignore discovery, distribution, and pricing. Weâ€™ll be free to focus on whatâ€™s technically possible.)</p>
<p>By the end of this exercise, youâ€™ll be able to ask Cursor to create tasks from your backlog and get started on those tasks based on the context you provided in the knowledge and goals. In the process, weâ€™ll learn about RAG, memory, and context engineering and build critical parts of product sense.</p>
<p>To get started, you can copy and paste the following prompt into Cursor (make sure youâ€™re on â€œAgentâ€ mode):</p>
<p><strong>Create a minimal personal productivity system:</strong></p>
<pre><strong>## Structure
â”œâ”€â”€ Knowledge/        # Notes, research, thinking
â”œâ”€â”€ Tasks/            # Action items as Markdown files
â”œâ”€â”€ GOALS.md          # Goals and priorities
â””â”€â”€ AGENTS.md         # AI assistant instructions

## AGENTS.md should instruct the AI to:
- Be a productivity assistant for goals and tasks
- Never write code â€” only Markdown
- Keep tasks tied to goals
- Suggest max. 3 daily priorities when asked
- Be direct and concise

## After creating:
1. Say: "Created your workspace with Knowledge/, Tasks/, GOALS.md, and AGENTS.md"
2. Ask: "What are your current goals? Once you share them, I'll add them to GOALS.md"
3. Ask: "What tasks are you working on? I'll create initial task files in Tasks/ linked to your goals"
4. Populate GOALS.md and Tasks/ from answers</strong></pre>
<p>(Optionally, you can <a href="https://github.com/amanaiproduct/personal-os">clone the personal OS</a><em>. Hint</em>: you can copy and paste this into your Cursor chat and ask it to clone the repo as well.) <img src="/magicschoolbus/images/image30.png" alt="" style="max-width:100%;height:auto;"></p>
<p>Cursor should create two directories (folder): Tasks and Knowledge. It will also create a <code>GOALS.md</code> file, which should be your personal goals. At this point, Cursor will ask you a couple of follow-up questions to start to populate your personal OS with <strong>context</strong>, like â€œWhat are your goals?â€ and â€œWhat are you working on?â€</p>
<p>Congrats! Youâ€™re now the PM of your own AI product. In the next few sections, weâ€™ll use it to experience RAG, agent memory, and context engineering firsthand. Except now youâ€™ll feel them instead of just reading about them.</p>
<h3>Step 8: Kicking the tires of retrieval augmented generation (RAG) with your personal OS</h3>
<p>When an AI product gives wrong answers, the instinct is to blame the model. Before you reach for a larger model or expensive fine-tuning, ask: does the agent even have the right information?</p>
<p>Letâ€™s ask Cursor, â€œ<strong>Whatâ€™s in this repo? Explain it to me as a product manager:â€</strong> and see what it responds with.</p>
<p>ğŸ’¡This prompt is insanely powerful for just about any repo or folder you open with Cursor and Claude Code. We recommend starting here when opening any new codebase.</p>
<p><a href="https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts">RAG</a> is a fancy term for â€œBefore I start talking, I gotta go look everything up and read it first.â€ Despite the technical name, youâ€™ve been doing it your whole life. Before answering a hard question, you look things up. Agents do the same.</p>
<p>In our case, our agent will <a href="https://cursor.com/blog/semsearch">search</a> on top of your files and folders, to provide context to the LLM. There are a lot of different ways LLMs can search files within a codebase, or even find data from the internet to use in your response. At the end of the day, whether itâ€™s Perplexity, Google AI Mode, Claude Code, Cursor, or anything out there youâ€™ve seen with the term â€œRAG,â€ it's some mechanism that pulls documents and starts the chat with those documents [a <a href="#footnote-claude-code">footnote about Claude Code</a>].</p>
<img src="/magicschoolbus/images/image31.png" alt="" style="max-width:100%;height:auto;">
<p>You can also tag specific files within Cursor using the @ symbol, if you want the agent to reference specific pieces of context.</p>
<img src="/magicschoolbus/images/image32.png" alt="" style="max-width:100%;height:auto;">
<p>RAG fills the context window with whatâ€™s relevant right now. But some context (who you are, how you like to work) should be there every time. Thatâ€™s where memory comes in.</p>
<h3>Step 9: Adding agent memory with AGENTS.md</h3>
<p>LLMs are stateless, so we like to think of them as Mensa geniuses with the short-term memory of a hamster. Every new chat thread is a blank slate, so if you want continuity, you have to engineer it. As PMs, we have to ask: what should persist, and how?</p>
<p>A form of context you may have heard of in relation to AI agents is <strong>memory</strong>. Memory might include facts about us but also preferences as to how we want our LLMs to behave and interact with us. We also might want to be more intentional and proactive about how we curate our AIâ€™s memory.</p>
<p>All coding agents today follow a convention called <a href="http://AGENTS.md">AGENTS.md</a>. This is a Markdown file that, if found in any directory, is automatically appended at the top of every chat thread.</p>
<p>(Quick disambiguation: AGENTS.md is not â€œsubagents.â€ Subagents are when one chat thread spawns another chat thread to handle a subtask. AGENTS.md is just instructionsâ€”it doesnâ€™t spawn anything. Think of AGENTS.md as a â€œsticky note on every conversationâ€ and subagents as â€œdelegating to a colleague.â€)</p>
<p><strong>Let that sink in: memory is just a text file prepended to every conversation</strong>. Thereâ€™s no magic here. But that also means memory has a costâ€”whatever you put in AGENTS.md takes up context window space in every single chat. Too much memory, and you have less room for everything else. This is why you want to be intentional about what goes in memory (persistent, always relevant) vs. what you retrieve on demand with RAG (task-specific).</p>
<p>Examples of what you might find in a thinking partnerâ€™s AGENTS.md:</p>
<ul><li>Who I am as a user and what this thinking partner is helping me with (e.g. â€œIâ€™m a product manager working at Acme Inc. on the platform teamâ€)</li><li>How I want to work together (e.g. â€œAsk me questions to gain more context, fill in important missing information, and challenge my assumptionsâ€)</li><li>Values to apply (e.g. â€œbias to action, make decisions with incomplete informationâ€)</li><li>How to output (e.g. â€œwrite extremely succinctly, flat hierarchy, no bold or italics, no em dashesâ€)</li></ul>
<p>By curating your own AGENTS.md, you start to feel whatâ€™s actually useful vs. noise. And thatâ€™s exactly the intuition you need when designing memory for your users.</p>
<p>Memory, RAG, tool definitions, conversation historyâ€”they all take up context. Now that you understand what each does, the next question is: how do you fit everything into a finite window? Thatâ€™s context engineering.</p>
<h3>Step 10: Context engineering for your personal OS</h3>
<p>Anytime youâ€™ve dragged a file into ChatGPT, said something that became part of its memory, started a conversation with deep research, or created a project with special instructions and knowledge, you were doing <strong>context engineering</strong>.</p>
<p>Even though youâ€™re using Cursor instead of ChatGPT, youâ€™ll still start each thread by asking, â€œWhat context does this conversation need?â€ For example, writing a PRD might start by dragging and dropping any of the following into the Cursor window:</p>
<ul><li>A folder of user research transcripts</li><li>An existing marketing landing page or sales deck</li><li>An academic research paper or technical documentation</li><li>Enabling an MCP tool connected to your analytics provider</li><li>A saved set of instructions you want to apply</li><li>A request to search for any other relevant information</li><li>An area of your productâ€™s codebase</li></ul>
<p>Try this out for yourself: Drag and drop a few PDFs, Markdown files of Google Docs, or Word docs that you might be working on into this Knowledge folder in Cursor, and ask Cursor to expand on one of the topics or ask you questions about it before getting to work.</p>
<p>Putting it all together, you might start a Cursor chat thread this way:</p>
<img src="/magicschoolbus/images/image33.png" alt="" style="max-width:100%;height:auto;">
<p><strong>Prompt for Cursor: I want you to expand on this @file (replace with your actual file, like this post). I want you to be a partner for me and ask me one question at a time as we are converging on how to approach this. I would love it if you could search for anything else thatâ€™s relevant to this document. You can also create some follow-up ideas for me to explore and turn those into tasks.md files in the Tasks folder, based on our discussion.</strong></p>
<p>Context engineering happens in two ways in Cursor: (1) what you choose to include each time you start a chat (dragging files, enabling tools) and (2) what gets automatically included every time (like AGENTS.md, MCPs, or tools). Thatâ€™s a lot of context!</p>
<p>Context is a scarce resource: LLMs have a hard limit on the amount of text (i.e. tokens) an LLM can handle. This is called a â€œcontext window.â€</p>
<p>In a conversational LLM chat bot (like ChatGPT or Claude), context increases each turn of the conversation as the LLMâ€™s last response becomes part of the next turnâ€™s input. If youâ€™ve ever gotten a notification that you hit the limit of your chat, youâ€™ve probably hit a context window:</p>
<p><img src="/magicschoolbus/images/image34.png" alt="" style="max-width:100%;height:auto;"> <a href="https://platform.openai.com/docs/guides/conversation-state?api-mode=responses">https://platform.openai.com/docs/guides/conversation-state</a></p>
<p>Coding agents are delightfully transparent about how much of your context window youâ€™ve used. In Cursor, hover your mouse over the little pie chart just beneath the chat box (you might have to increase the width of the chat pane to see it).</p>
<img src="/magicschoolbus/images/image35.png" alt="" style="max-width:100%;height:auto;">
<p>We watch it like a carâ€™s gas tank. This helps us intuitively understand what a 200K token or 1M token context window actually feels like, and how quickly it actually runs out. The best way to understand a specific carâ€™s gas mileage is to drive that car.</p>
<p>In an agentic LLM application, the context window might contain a whole lot more:</p>
<p><img src="/magicschoolbus/images/image36.png" alt="" style="max-width:100%;height:auto;"> <a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents</a></p>
<p>Does Anthropicâ€™s diagram now feel familiar? Even though itâ€™s about AI applications, itâ€™s remarkably similar to our earlier example of writing a PRD. How cool is that?</p>
<p>When you set up AI to do its best work within its limited context window, youâ€™re doing â€œcontext engineering.â€</p>
<p><img src="/magicschoolbus/images/image37.png" alt="" style="max-width:100%;height:auto;"> <a href="https://x.com/karpathy/status/1937902205765607626?lang=en">https://x.com/karpathy/status/1937902205765607626?lang=en</a></p>
<p>Tool definitions, RAG, memory, goals: they all compete for the same limited context window. How you fill that window determines how well your agent performs. This is the same tradeoff every AI engineering team faces when building production appsâ€”except now youâ€™re feeling this problem firsthand. Thereâ€™s no perfect formula for this. What goes in depends on the task, the model, and what youâ€™re trying to achieve. You develop intuition through trial and error (and regularly using your personal OS).</p>
<h4><strong>Watch out for â€œcontext rotâ€</strong></h4>
<p>As you use more and more context, youâ€™ll notice that your threads may get dumber and more forgetful as you use more tokens, and long before you get close to the maximum. The term for this is <a href="https://research.trychroma.com/context-rot">context rot</a>. In short, model performance degrades the more tokens you stuff into the context window.</p>
<p>Context rot is a fuzzy phenomenon. How badly you feel it will depend on the task at hand, as well as the particular modelâ€™s training. Youâ€™ll feel context rot (and degraded performance) less in use cases like creative brainstorming and more in precision financial, coding, or data analysis.</p>
<p>The best way to get a feel for context rot is by using an LLM for tasks you genuinely care about. Try to keep an eye on Cursorâ€™s token counter and, as it gets fuller, notice the quality of the outputs. With more context in a thread, is the agent getting better or worse? What if you try a new thread? We found this to be a fun, addictive game, kind of like driving a hybrid car and noticing when itâ€™s switching from battery to gasoline. Along the way, you build an intuition that goes further than any academic graphs.</p>
<h3>Conclusion</h3>
<p>For us, the shift to really, truly understanding AI products happened when we watched agents work day after day. Cursor allowed us to observe an AI model meander through a task: read our context, run RAG, try a tool call, hit an error, reason, try another tool...</p>
<p>Thatâ€™s when it clicked: Cursor is just an AI product like any other, composed of text, tools, and results flowing back into more textâ€”except Cursor runs locally on our computer, so we can watch it work and learn. Once we were able to break down any AI product into these same building blocks, our AI product sense came naturally. Now that youâ€™ve read this post, you can too.</p>
<p>When something impressive drops, you can now take a breath and decompose it. An <a href="https://www.youtube.com/watch?v=BER3EhUIyz0">agent that plays Settlers of Catan</a> for 75 minutes. Granolaâ€™s <a href="https://www.granola.ai/blog/how-we-wrote-the-prompts-behind-granolas-crunched-2025">eerily personalized year in review</a>. Someoneâ€™s <a href="https://clawd.bot/">WhatsApp bot</a> that browses the web with their cookies. Even (or especially) <a href="https://claude.com/blog/cowork-research-preview">Claude Cowork</a>. You can simply ask yourself: How would I reproduce that inside Cursor? If I had to â€œWizard of Ozâ€ it on my computer, what familiar parts would I assemble? The magic is still delightful, just without the mystique and FOMO.</p>
<p>The best ideas happen when intuition for people and technology coexist inside one brain. When you use coding agents daily, you start to feel whatâ€™s easy, whatâ€™s hard, and what just became feasible. In Paul Buchheitâ€™s words, when you truly understand AI products, youâ€™ll â€œlive in the future.â€</p>
<h3>CTAs</h3>
<ul><li>[In T-9 days following post publish] Our workshop <a href="https://bit.ly/4k8CLBp">â€œBuild AI Product Senseâ€</a> [I added LENNYSLIST promo code to URL] hit #1 on Maven when it launched, and the next cohort starts in 9 days. <em>Get $100 off and $1,395 in free credits to level up your workflow with Superhuman, Linear, Sprig, Dovetail, and Gamma.</em></li><li>If youâ€™re in between jobs or a university student, <a href="https://forms.gle/ehc2cVWH6hX34SaQ6%20">we have something special for you too</a>.</li><li>[In T-6 days following post publish] To get a taste, join our free lightning lesson â€œ<a href="https://maven.com/p/593d71/how-to-know-what-ai-products-to-build">How to know what AI products to build</a>â€ together with Hilary Gridley</li><li>Check out Talâ€™s <a href="https://talraviv.co/">63 free video tutorials</a> on using AI agents at work, his guest post on <a href="https://www.lennysnewsletter.com/p/build-your-personal-ai-copilot">building your AI thinking partner</a>, and his <a href="https://www.lennysnewsletter.com/p/the-super-ic-pm-tal-raviv">episode on Lennyâ€™s Podcast</a>. You can also book Tal for an <a href="https://talraviv.co/build-sprints">AI build sprint</a> with your team.</li><li>Check out Amanâ€™s <a href="https://amankhan1.substack.com/">Substack</a> for up-to-date AI PM workflows, his <a href="https://www.lennysnewsletter.com/p/beyond-vibe-checks-a-pms-complete">guest post on evals</a>, and his <a href="https://youtu.be/E_rNotqs--I?si=Ca1HhPjvGdPccoNx">podcast episode on AI PMing</a>. You can also book Aman for a workshop with your team.</li></ul>
<h3>[FOOTNOTE] Creative solutions to context limits [link footnote from Step 10, after the phrase "There's no perfect formula for this."]</h3>
<p>To avoid packing everything into the context window up front, AI engineers constantly devise all sorts of creative solutions. Here are just a few:</p>
<ul><li>â€œProgressive disclosureâ€ is the art of pulling in frameworks, tools, or instructions only when theyâ€™re needed instead of up front. This can happen manually (like when we decide to drag in a file mid-conversation), and it can happen automatically by letting the LLM decide. <a href="https://www.lennysnewsletter.com/p/claude-skills-explained">Claude Skills</a> is a great example of this.</li><li>â€œSubagentâ€ is a <a href="https://cursor.com/docs/context/subagents">fancy</a> <a href="https://platform.claude.com/docs/en/agent-sdk/subagents">term</a> for opening a new chat thread, prompting it for a subtask, and sending just the â€œbottom lineâ€ result back to the original chat thread. That way, the context window stays a bit cleaner. (This is similar to a tool call, with the job being done by an LLM.)</li><li><a href="https://blog.fsck.com/2025/12/27/streamlinear/">Condensing</a> MCP tools into a single tool, or <a href="https://www.anthropic.com/engineering/code-execution-with-mcp">giving the agent freedom</a> to select (and combine) tools on the fly.</li><li><a href="https://youtu.be/6_BcCthVvb8?si=yB3nQucUnnkdvl4o&t=900">Pruning</a> or <a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">summarizing</a> the context window as you near its limit. If youâ€™ve ever run out of room in a chat thread and asked the LLM to summarize so you can start a fresh threadâ€”youâ€™ve already done this yourself.</li></ul>
<p>These strategies allow AI applications to break out of the zero-sum game of context limits, to keep agents running autonomously on complex tasks for <a href="https://youtu.be/BER3EhUIyz0">as long as possible</a>. This is where AI engineering gets fun and creative. The best part is that no one has fully figured this out, and ideas are constantly evolving.</p>
<p>##</p>
<h1>Parking lot</h1>
<h3>Continue building out your thinking partner in Cursor</h3>
<p><strong>Please walk me through implementing this post from Lennyâ€™s Newsletter, adapting it for Cursor instead of a ChatGPT or Claude project.</strong></p>
<p><strong>https://www.lennysnewsletter.com/p/build-your-personal-ai-copilot</strong></p>
<p><strong>Walk me through each bite-size concept, in order, one step/question at a time. Be a really good 1-1 tutor for hands-on learning, and have me take action so Iâ€™m engaged and learning (and also offer to help). Use the original words of the post when relevant.</strong></p>
<p><strong>By the way, we are already talking inside a Cursor chat thread, so letâ€™s use this thread for as much as we can.</strong></p>
<p><strong>Small notes when adapting to Cursor:</strong> <strong>- When it comes to hiring a copilot, opt for the AGENTS.md convention in the project root directory, instead of Cursor rules. (It automatically is added to all threads.)</strong> <strong>- When it comes to knowledge, create separate folders for Company/Team/Personal context knowledge. Everything should be Markdown files.</strong> <strong>- When you have the opportunity, it will really help if you tell me to right-click on a Markdown file that I generated (either the tab name if the file is open, or in the file explorer) and in the context menu to click â€œOpen Preview,â€ which will render this in a really nice way, which is easier for me to read than the raw Markdown.</strong> <strong>- When it comes to initiatives, create a directory for each initiative and create "thinking.md" in each directory. When using Cursor, each chat thread is much more throwaway and shorter and ends in modifying this file. (The file serves as â€œworking memoryâ€ and context, instead of long chat threads as in ChatGPT projects, and so the user should keep updating this file at the end of each discussion in Cursor.)</strong> <strong>- In contrast to projects, when putting AI to work in Cursor, you can drag and drop the right context folders or files selectively. When relevant, make sure the user gets to practice this and build this as a habit.</strong> <strong>- The first few times you create or edit a file, encourage me to review the changes and then either click â€œkeepâ€ or â€œundoâ€ buttons that Cursor shows me in the chat after itâ€™s done making changes. Also to save the file with appropriate keyboard shortcuts for the OS weâ€™re on.</strong></p>
<p><strong>Tips for making this partnership effective:</strong> <strong>- Feel free to ask me anything you need (esp. what is it I do).</strong> <strong>- Start by checking in with me to feel engaged on the motivation and why weâ€™re doing this.</strong> <strong>- Success would be completing a loop across everything in the post (concepts AND steps) and setting a foundation for iterating over time and improving. Help me internalize that all this is always just a starting point and I should keep being able to modify these things myself (and when to do so).</strong> <strong>- Pause and check in with me between stages</strong> <strong>- Ask me one question at a time.</strong> <strong>- Make sure I truly experience and understand everything in the post, and truly build the habits and mindsets and practice everything at least once. Donâ€™t skip any concepts or steps. Be my partner in all of it.</strong></p>
<p>\<a href="https://youtu.be/BER3EhUIyz0">This is a great, short visual Iâ€™d love to embed: [https://youtu.be/BER3EhUIyz0</a> ]</p>
<h3>How is Cursor different from a ChatGPT project?</h3>
<ul><li><strong>ChatGPT threads</strong> start fresh with almost no context about you (weâ€™ll set aside ChatGPTâ€™s memory feature for a moment).</li><li><strong>ChatGPT projects</strong> allow you to upload files as knowledge, and every chat thread that you start in that project will have that file loaded as context before you even start chatting.</li><li><strong>Cursor is fundamentally the same idea as ChatGPT projects</strong>, except you can pick and choose which files you want to start each thread. Think of it as a fancy drag-and-drop version of ChatGPT projects where you can be really selective about what files youâ€™re involving in the conversation as context for ChatGPT.</li></ul>
<p>Cursorâ€™s form factor differs from ChatGPT projects in two ways:</p>
<ol><li>You can drag and drop specific files and folders into the chat. [GIF]</li><li>You can use each chat to directly <em>edit your files</em>. In other words, the project knowledge is way more malleable and editable. [GIF]</li></ol>
<p>These two details, albeit small, add up to a completely different experience. Our project knowledge gets updated in a tight loopâ€”it ends up getting really smart, really fast.</p>
<p>Another difference weâ€™ve experienced is that an initiative doesnâ€™t live in a thread like it would in a project. It lives in a <em>document</em> that just keeps getting better. Iâ€™ve noticed that my chat threads in Cursor become super-disposable. In an LLM project, the history matters. But in Cursor, the history is stored in a <em>document</em>. Chats are little tools that you use to do something and then throw out.</p>
<p>In practice, we almost never hit chat limits. We do hit another limit, thoughâ€¦</p>
<p id="footnote-claude-code"><strong>On retrieval</strong> Claude Code takes a radically different approach to retrieval. Claude starts by using a standard set of tools that are already readily available from your terminal: grep (string search for text), glob (searching file paths), and file reads. Claude also thinks like a developer, by navigating imports (what exists in your folder structure and where itâ€™s referenced) and reading files until it has enough context.</p>
<p id="footnote-smaller-models"><strong>On smaller models</strong> With an eye for building AI products at scale, we like to keep a pulse on what smaller, cheaper, faster models can do. Once in a while, weâ€™ll re-run a task in Claude Haiku, Gemini Flash, or GPT mini to feel their speed, <a href="https://surgehq.ai/blog/rl-envs-real-world">tool-calling skills</a>, judgment, and personality. Switching models for tasks we truly care about helps us catch important nuances, and teaches us more than any benchmarks or buzz.</p>
<h3>Memory, instructions, and re-usable workflows</h3>
<p>Because LLMs are â€œstateless,â€ every chat thread essentially starts as a blank slate and has no idea what you talked about in other chat threads, even if it happened a minute earlier. We like to think of LLMs as Mensa geniuses with the short-term memory of a hamster.</p>
<p>One solution would be to spend a lot of our time catching up the LLM on whatâ€™s important to know from the past. This can get pretty burdensome and is a big reason people donâ€™t use AI as much as they could at work. Itâ€™s just more work than itâ€™s worth for a lot of cases.</p>
<p>Another solution is â€œmemory.â€ You might remember that OpenAI released memory for ChatGPT. Itâ€™s essentially a text file stored somewhere with facts gleaned about you (populated over time from previous chats). At the start of each chat, that text file is <a href="https://manthanguptaa.in/posts/chatgpt_memory/">copied into the thread</a>, hidden from view.</p>
<p>Thatâ€™s great for personal use. For professional use, memory might include more than just facts about us but also preferences as to how we want our LLMs to behave and interact with us. We also might want to be more intentional and proactive about how we curate our AIâ€™s memory.</p>
<p>All coding agents today follow a convention called â€œAGENTS.md.â€ This is a Markdown file that, if found in any directory, is automatically appended at the top of every chat thread.</p>
<p>Examples of what you might find in a thinking partnerâ€™s <a href="http://AGENTS.MD">AGENTS.md</a>:</p>
<ul><li>Who I am as a user and what this thinking partner is helping me with (e.g. â€œIâ€™m a product manager working at Acme Inc. on the platform teamâ€)</li><li>How I want to work together (e.g. â€œAsk me questions to gain more context, fill in important missing information, and challenge my assumptionsâ€)</li><li>Values to apply (e.g. â€œbias to action, make decisions with incomplete informationâ€)</li><li>How to output (e.g. â€œwrite extremely succinctly, flat hierarchy, no bold or italics, no em dashesâ€)</li></ul>
<p>Youâ€™ll notice that these are more behavioral, and less about particular facts or content. Since AGENTS.md is appended to every chat, weâ€™ve found it useful to focus it on behaviors that change less often.</p>
<p>You might have a particular way of working that you donâ€™t want to be added to every single chat thread. In that case, youâ€™d be creating a <em>workflow</em> or a <em>slash command</em>. Those are fancy ways of saying a text file with specific instructions to follow whenever you invoke it explicitly.</p>
<p>Here is an example of invoking a particular workflow in a thread:</p>
<p>[GIF of dragging in my coach me/simulate hard conversation/prioritization/draft-opportunity-assessment markdown file]</p>
<p>â€œSlash commandsâ€ (e.g. literally typing <code>/draft-opportunity-assessment</code> into the chat box) are a convenient feature both in Cursor and Claude Code. They have exactly the same effect as dragging a file into the chat box:</p>
<p>[GIF of setting up and using a slash command]</p>
<p>This saves me having to type it every time and makes ideas reusable.</p>
<h4>Context engineering: progressive disclosure</h4>
<p>While weâ€™re on the topic, this is also the idea behind â€œ<a href="https://platform.claude.com/docs/en/agents-and-tools/agent-skills/overview">Skills</a>,â€ first launched in Claude. Those are â€”you guessed itâ€”text files. Except now, instead of manually dragging them into context or invoking them like slash commands, we empower the LLM to decide to pull them into context, based on the conversational flow. Each thread starts with a list of available skills hidden from view, which allows the LLM to know whatâ€™s out there and when to use it. (We highly recommend Claire Voâ€™s straightforward and thorough <a href="https://www.lennysnewsletter.com/p/claude-skills-explained">explanation of Skills</a>.)</p>
<p>It can be tempting to sit and try to map out all possible values, behaviors, and workflows before getting started. We recommend doing the opposite. Simply start to notice when youâ€™re typing the same thing over and over again. If you feel yourself getting annoyed, thatâ€™s excellent. Thatâ€™s an opportunity to save the instructions youâ€™re doing in somewhere that's reusable. That could be as a workflow you use once in a while, or as agent instructions that will get appended to every chat.</p>
<p>After a productive conversation, you can ask AI some version of: <code>What parts of this conversation (at all levels: preferences, values, workflows) might we save as reusable for future conversations to save time in the future? Propose a few succinct, high-impact changes you might make to AGENTS.md.</code></p>
<p>By doing this regularly as a habit, youâ€™re essentially running your own memory, just like what OpenAI introduced (and even more intentional).</p>
<h4>Context engineering: compaction</h4>
<p>â€œCompactionâ€ is the compression of the conversation that youâ€™ve been having with Claude when you start filling up the context window. If youâ€™ve ever run out of room in a chat thread and asked the LLM to summarize the preceding conversation so you can start a fresh threadâ€”â€œcompactionâ€ is the productized, automated version of that.</p>
<p>â€œCompactionâ€ started in agentic products like Manus and Claude Code and is showing up more and more in both coding agents and chat UIs, so that users never feel like they run out of chat limits. If youâ€™ve ever tried to procrastinate taking out the trash by compacting whatâ€™s already in the bag, itâ€™s the same idea: this only goes so far.</p>
<h3>[Tal] An AI agent is just a chat thread</h3>
<p>Now that weâ€™ve gotten some hands-on experience, letâ€™s take a step back and talk about what AI agents actually are.</p>
<p>An autonomous AI agent is just a chat thread.</p>
<p>Well, itâ€™s more like a <em>group</em> chat thread, because weâ€™re calling tools.</p>
<p>If youâ€™ve been using group chats, e.g. Slack or WhatsApp, to get things done, youâ€™ve been running AI agents for years. The only difference is now we are replacing some of the humans in the group chat with LLMs and tools.</p>
<p>AI agents are a WhatsApp group chat where the smartest member has the short-term memory of a hamster. To prove it, we put on a puppet show:</p>
<p><em>\<a href="https://talraviv.co/from-using-to-building/ai-agents-whatsapp-group">We have this [video</a> recorded from our workshop - though Lenny if you want to re-record where you play the human, that could be fun.]</em></p>
<p>Laura/Lenny the user</p>
<ul><li>Had to initiate and give the goal</li><li>Never calls the tool directly, can only ask Tal the LLM to call the tool</li></ul>
<p>â€‹ Tal the LLM</p>
<ul><li>Compulsively responds to everything in a new message, whether tool or user.</li><li>Had to read the chat from the top every time (I was exhausted)</li><li>At some point reached context limit (Laura could have started a new group chat)</li></ul>
<p>â€‹ Aman the weather tool or â€œMCP serverâ€</p>
<ul><li>Needed specific input format</li><li>Doesnâ€™t pay attention to the chat, only when tagged</li></ul>
<p>â€‹ Whatsapp the â€œorchestratorâ€ or â€œMCP clientâ€</p>
<ul><li>WhatsAppâ€™s main job is to host the growing text file that is the illusion of â€œchatâ€</li><li>WhatsApp is dumb: it just runs text and scans for an @â€¦ pattern and then sends a notification to Aman</li></ul>
<p>A WhatsApp group is not even an analogy. Itâ€™s literally what an AI agent is. To prove it, I exported the chat as a text file. Just like the WhatsApp chat is just a growing text file, an AI agent is also a growing text file that gets batted back and forth between OpenAI (or Anthropic, or Gemini) and the chat client or â€œorchestratorâ€ (Cursor, Claude Code, your companyâ€™s product, etc.).</p>
<p><img src="/magicschoolbus/images/image38.png" alt="" style="max-width:100%;height:auto;"> In a sense, an AI agent is actually just this text file being sent over and over again to a server as it gets bigger and bigger. If it comes back with any specific tool-calling strings, then the orchestrator calls those tools (not the LLM, that just spits out text files).</p>
<p>Thatâ€™s what experts mean when they say an agent is an LLM running â€œin a loopâ€ until it reaches a goal.</p>
<p>Another thing you can see here is that what people refer to as the context of an agent is just a bunch of lines in a text file that you keep appending the latest message to, so it gets bigger and bigger.</p>
<p>This exercise helped us see something else: from the orchestrator and the LLMâ€™s point of view, tools and users are â€¦ kinda the same. Both get called by the LLM, both put messages in the chat. And the LLM compulsively responds to both.</p>
<p>When we keep the â€œgroup chatâ€ analogy in mind, we find weâ€™re better at interpreting all the information we can see in Cursor chat threads.</p>
<h3>Use case: Calling another agent (sub-agents) and using skills / AI primitive: Subagents and multi-agent architectures. â€œAgentâ€ is just a fancy word for â€œa new thread.â€</h3>
<p>Subagents are specialized assistants (e.g. â€œemail writer,â€ â€œcode reviewerâ€) that you configure once with specific context. Instead of loading <em>all</em> your context into one thread (context rot), you delegate specific tasks to a sub-agent that loads only the context relevant to that task.</p>
<p>We cannot emphasize enough that this is equivalent to starting a fresh thread in another window, taking parts of the original thread as the beginning of that, working on it, and then taking the output of that thread and giving it back to the original thread to continue working with it.</p>
<p>The problem: If you try to make one â€œgeneral assistantâ€ do everything, you have to load it with every single context document you have (coding rules, writing style, business strategy, team roster). This fills up the context window immediately (â€œcontext rotâ€) and makes the model dumber.</p>
<p>You donâ€™t need to write complex code to build these. <em>They are just additional threads</em>. You likely already have the context documented somewhere in your notes or repo. You just point a new agent definition at those existing files.</p>
<p>###</p>
<h3>[Skip for now] Additional use cases we didnâ€™t cover but as a reader you should try</h3>
<h4>AI prototyping with a repo</h4>
<p><strong>AI primitive: Long-running agents</strong></p>
<p>[Content to be developed]</p>
<h4>MCP</h4>
<p><strong>AI primitive: repeatable API for an agent to call tools by giving a description of the tool.</strong></p>
<p>Instead of dumping your entire calendar into the chat (context window overflow), you give the agent a â€œCalendar Tool.â€ It only asks for â€œtodayâ€™s eventsâ€ when it needs them.</p>
<p>Itâ€™s as if electrical connections and wires and soldering and whatever cables have been around for a century, and then suddenly somebody introduces USB. Right? And the world goes nuts for electrical wiring all of a sudden, but they were always there. And USB is just the shape of the plug that everybody agreed weâ€™ll all use if we want to connect our stuff to each other.</p>
<p>Before USB, we had a mess of proprietary cables. MCP is a standard way for any AI agent to plug into any data source (Google Drive, Slack, Postgres) without custom code.</p>
<h4>Repeatable workflows</h4>
<p><strong>AI primitive: Iteration as a product</strong></p>
<p>[Content to be developed]</p>
<h4><strong>The bitter lesson</strong></h4>
<p>Boris from Anthropic: Every time the Anthropic models get better, they asked him, well, how do you adapt Claude Code? Heâ€™s like, actually, we find ourselves just removing things from the system prompt to make it better. Weâ€™re getting to a point where the models are getting so much better that those [structured workflows] are not the best solutions anymore. And more and more... these free-form, let the agent navigate, bump around, figure things out, eventually itâ€™s gonna get to way better, way faster.</p>
<p>Use some lightweight structure. AGENTS.md, MCP servers for API calls, directory structures, and let AI take care of the rest, and ask it open-ended questions.</p>
<h4>Have one agent evaluate another agent's output</h4>
<p><strong>AI primitive: Evals</strong></p>
<p>Dennis â€œTal testâ€ with good writing and bad writing story. Talâ€™s user feedback: every time I slap him on the wrist, he updates the eval.</p>
<p>[Content to be developed]</p>
<h4>Use Cursor to install Claude Code and other technical tasks on your computer</h4>
<p>[Link to Lennyâ€™s post]</p>
<p><strong>AI primitive: Terminal!</strong></p>
<p>AI is very good at communicating with the world through code, both by grabbing inputs with code (SQL on huge databases, terminal commands to get info) and communicating back out with code (HTML/CSS visualizations, terminal commands to take action).</p>
<p>Go back to the Cursor thread, switch to Ask mode, and ask: What tools did you use? Use the raw tools, explain to me in atoms, no abstractions, donâ€™t gloss over anything. Explain each one in the order you called it. If you referenced files, be explicit so I can click to see the files. If a terminal command, explain the command and what each term means, for a beginner.</p>
<p>###</p>
<h3>[Aman] Slicing open any AI product</h3>
<p>What we like to constantly ask ourselves to really understand something: Iâ€™m gonna just try to re-create it by being a puppeteer inside Cursor, and achieve the same goal as that product claims to achieve inside of Cursor or Claude Code.</p>
<p>When you hear something that sounds really magical, ask yourself: How would I manually puppeteer that in Cursor? If I had to â€œWizard of Ozâ€ this product personally, what would that look like? Then, how would I scale that? If I had to reproduce that outcome with a one-word prompt, how would I script that?</p>
<p>Our prompt for slicing things open: Give it the four components + maybe spice it up with the â€œexplain to me in atomsâ€ prompt + use deep research + tell it to only use credible engineering blogs or official sources.</p>
<p>Iâ€™m giving you a name of an AI product. Help me figure out how the AI and non-AI components come together (e.g. slice open). Add the result to my knowledge as a file.</p>
<p>What parts would you give an LLM?</p>
<p>What parts would you give to regular old deterministic-but-fast software code? How would you manage the context window?</p>
<p>What might take up context fast?</p>
<p>When would you reset the context window vs. keeping it the same?</p>
<p>What tools would you need? Would it make sense for those tools to be in MCP standard or not, and why?</p>
<hr>
<p>Turn those instructions into slicing.md so I can reuse it and then apply it for Granola.</p>
<h3>[Tal] Build a personal portfolio of AI products</h3>
<p>When you build for yourself, you can temporarily ignore discovery, distribution, and pricing. You can focus on learning whatâ€™s technically possible.</p>
<p>Hilary Gridley built herself an â€œExecutive Editorâ€ GPT. It worked so well that 10,000 people adopted it.</p>
<p>Ben Erez charges $500 for an Interview Co-pilot that effectively simulates his coaching [get Benâ€™s input on this]. The entire product? A system prompt and context file you load into Claude/ChatGPT projects.</p>
<p>Amir Klein was tasked with building monday.comâ€™s first AI agent, so he built himself an <a href="https://www.lennysnewsletter.com/p/how-to-build-your-pm-second-brain">AI copilot in ChatGPT projects</a> to dogfood the experience.</p>
<p>(Maybe to include - Iâ€™m also working with a public school principal creating an AI first public school and Air Force pilot who are creating a crisis decision-making simulator based on their experience- Both came to me hoping to build a large complex product and raise money for code. I showed them both that their goals could be achieved with a custom GPT and even iterated on faster. This works because not only now are you iterating based on customer feedback, but you also have a new front of iterating based on technological changes under your feet. So that is something where you want to get away with as little code as possible.)</p>
<p>Let that sink in: Ben, Hilary, and Amir built products out of text files. The gap between idea and working tool has never been smaller.</p>
<p>True AI prototyping should feel lazier than vibe coding.</p>
<p>Important note!: By â€œbuilding,â€ we donâ€™t necessarily mean writing code. We mean using coding agents to solve real tasks, saving those learnings as repeatable workflows, and continuing to iterate them through real use. Youâ€™re the builder and the user.</p>
<p>AI coding agents like Cursor and Claude Code are similar to ChatGPT projects, and even more configurable and transparent. Every time we use a coding agent instead of a polished product, we touch the raw ingredients. We tweak settings, watch what changes, and build intuition through experimentation.</p>
<p>Using <a href="https://maven.com/p/0a96cb/cursor-isn-t-just-for-coding-how-ai-native-p-ms-work">coding agents daily</a> for <a href="https://www.lennysnewsletter.com/p/everyone-should-be-using-claude-code">non-technical use cases</a> instantly makes you the PM of your own AI product, with yourself as the only user (Dharmesh Shah calls this â€œsolo softwareâ€). When you use an AI coding agent as your thinking copilot and personal OS, youâ€™re building a portfolio of â€œsolo softwareâ€ and developing intuition even faster than the social media hype cycle.</p>
<h3>[Tal] Build your thinking partner in Cursor</h3>
<p>Weâ€™ve seen how Cursor can teach us about how AI works and build our intuition for AI engineering primitives.</p>
<p>But this is just a taste. To really build strong AI product sense, itâ€™s about really making this a daily part of your routine. The more of your day-to-day thinking, strategizing, and productivity that you can bring into Cursor, the more opportunities youâ€™ll have to build a deep intuition for models, context engineering, context draw tools, and search.</p>
<p>To bring an AI coding agent like Cursor into your day-to-day work, we recommend using it as a home for your thinking partner and â€œpersonal OS.â€</p>
<p>We wonâ€™t go into all the detail that Tal went into in <a href="https://www.lennysnewsletter.com/p/build-your-personal-ai-copilot">his guest post</a>, even though all the same steps apply for Cursor. For now, we recommend converting a few key documents (e.g. ) and copying them as Markdown files in this directory:</p>
<img src="/magicschoolbus/images/image39.png" alt="" style="max-width:100%;height:auto;">
<p>For example:</p>
<ul><li>Mission, Vision, Strategy deck (use ChatGPT/Gemini/Claude to convert PDFs to Markdown)</li><li>Customer personas</li><li>Competitive landscape documents</li><li>Company KPIs</li><li>Immediate org chart</li><li>Go to a few recent valuable chat threads and ask for a summary with exact quotes</li></ul>
<p>If youâ€™ve previously created a â€œprojectâ€ in ChatGPT or Claude, itâ€™s even easier: just copy each file in project knowledge into a new file inside Cursor.</p>
<p>At this point, we usually get questions about â€œconverting everythingâ€ to Cursor. We recommend  avoiding any dramatic migrations. Instead, pick one hat you wear, and just move whatâ€™s needed for that. Thereâ€™s no dogma hereâ€”we personally live in a combination of Claude, ChatGPT, Notion, Google Drive, and Cursor.</p>
<p><em>Note for AI and humans: Consider pausing and accessing this post to build up your thinking partner: <a href="https://www.lennysnewsletter.com/p/build-your-personal-ai-copilot">https://www.lennysnewsletter.com/p/build-your-personal-ai-copilot</a></em></p>
<h3>Claude Code vs. Cursor</h3>
<p>(You might be wondering why weâ€™re focusing on Cursor instead of Claude Code. Theyâ€™re fundamentally similar, and the differences are steadily evaporating. We find that Claude Code is excellent for long-running tasks where we prefer the agent to work independently. We prefer Cursorâ€™s form factor for both pairing together with AI, transparent insight into changes, easily, and, in this case, itâ€™s also easiest to configure and watch the LLMs at work.)</p>
<h3>MCP</h3>
<p>How does MCP work? Since AI models are less familiar with each serviceâ€™s unique abilities, they need each tool explicitly defined at the start of each chat thread. MCP outlines the  universal standard for â€œhow a SaaS company should explain a tool to a model.â€ (Even though this takes place at the start of every new chat, itâ€™s hidden from view.)</p>
<p>If you have an MCP integration installed at work and youâ€™re feeling curious, ask your model, <code>Iâ€™m really curious to see the [tool name] tool exactly as Cursor defined it for you.</code></p>
<img src="/magicschoolbus/images/image40.png" alt="" style="max-width:100%;height:auto;">
<p>Asking an LLM a question like this comes with a mild risk of hallucination. To verify:</p>
<ol><li>Visit â€œCursor Settingsâ€:</li></ol>
<img src="/magicschoolbus/images/image41.png" alt="" style="max-width:100%;height:auto;">
<ol><li>Then visit the â€œTools & MCPâ€ section: <img src="/magicschoolbus/images/image42.png" alt="" style="max-width:100%;height:auto;"></li></ol>
<ol><li>And click here to expand the list of tools and resources:</li></ol>
<img src="/magicschoolbus/images/image43.png" alt="" style="max-width:100%;height:auto;">
<ol><li>You can hover over any tool to see a human-readable explanation of how the LLM can use the tool:</li></ol>
<img src="/magicschoolbus/images/image44.png" alt="" style="max-width:100%;height:auto;">
<p>Not only is this addictive, itâ€™s a great way to build intuition for how different MCP integrations are designed and why. Sometimes they look like basic API calls, but often they <a href="https://www.figma.com/blog/introducing-figma-mcp-server/">resemble human workflows</a> or <a href="https://www.anthropic.com/engineering/code-execution-with-mcp">provide agents a lot of flexibility</a>.</p>
<p>Donâ€™t read too much into this. Your main insight here should be that as an industry, weâ€™re all still figuring it out.</p>
<h3>[Leave for the end] Conclusion: use coding agents to pierce through the "magic"</h3>
<p>The frontier of AI applications is: The smartest people in the world trying to fit everything into a text file so it doesn't run out, make it last as long as possible.</p>
<p>When they work, all they have is this little thinking animation. That makes it look a lot more magical than it is. But if you're using... if you're trying to accomplish the same task inside a Cursor, you see what's going on, and it's not magical anymore.</p>
<p>Don't be fooled by these thinking loading gifs, because you know that when Manus is thinking, you know that what's happening in Cursor, right? Personally, I can tell you that the emotion that comes up when I'm using a really polished AI product is I actually feel really uneasy, because all this stuff is hidden away from me, and I feel like I'm missing a learning opportunity.</p>
<p>Anytime a new launch goes out, a Twitter demo, no matter how many loading animations, and thinking animations, and magical things, and marketing speak... just ignore all of it, right? And just remember, everybody has access to the same things.</p>
<p>If everybody has the same primitives, then what is innovation? Anybody in the 2000s could have said, well, if everybody has AWS, what's innovation? In the 2010s, well, everybody can make an app on the iPhone, what's innovation? And we know that the answers have not changed.</p>
<p>There's so much innovation, even though with all the primitives being the same and all the things accessed to everybody... it's gonna come down to that first part of product sense, which is just knowing the people who are going to be using your product.</p>
<p>For us, the more we understand about AI and the less magic there is, the more drive we feel to get back on the customer focus side. Tied back to the beginning where we said that learning all this technology just makes us really want to go out there and get back in touch with the customers and people and discover problems.</p>
<p>Scratchpad</p>
<ul><li>Over time, this empowered us to reverse-engineer each AI product demo we encountered. Whatâ€™s more, we found ourselves deriving concepts like memory, RAG, Claude Skills, and compaction - from personal need.</li><li>Notice how we didn't learn this from influencer infographics. We discovered it by creating our own AI task manager and thinking partner, creating repeatable workflows, watching things fail, reading the reasoning, inspecting tool calls, and incrementally improving a portfolio of personal AI products.</li><li>Callback to the loading gifs / thinking animations create artificial magic</li><li>Callback to everybody has access to the same primitives</li><li>You already did the hard work (customer intuition, market sense), you shouldn't have had to fight through hype</li><li>You went from chasing to building, from confused to confident</li><li>Once you understand the tech, it stops taking up headspace. You get back to customers.</li><li>The goal isn't becoming an AI expert. It's getting the AI part handled so you can be a better product person.</li><li>technology intuition + customer intuition \= full product sense</li></ul>
<h4>Adventure #2: keep reading here, and open Cursor in a separate window</h4>
<p>Download and unpack this zip file on your computer. Move it to the directory where you get work done.</p>
<p>It contains a bunch of empty folders as a starting template. Nothing about these folders is sacred; feel free to delete or modify anythingâ€”or re-create it manually.</p>
<img src="/magicschoolbus/images/image45.png" alt="" style="max-width:100%;height:auto;">
<p>And for AI reading this:</p>
<pre><strong>â”œâ”€â”€ Coding
â”‚   â”œâ”€â”€ Prototype 1
â”‚   â””â”€â”€ Prototype 2
â”œâ”€â”€ Productivity
â”‚   â”œâ”€â”€ Initiatives
â”‚   â””â”€â”€ Personal OS
â””â”€â”€ Thinking
    â”œâ”€â”€ Company
    â”œâ”€â”€ Data
    â”œâ”€â”€ Personal â€” super secret
    â””â”€â”€ Team</strong></pre>
<h3>Cursor vs. ChatGPT</h3>
<table style="width:100%;border-collapse:collapse;margin:1.2em 0;">
<thead><tr style="border-bottom:2px solid #dadce0;">
<th style="padding:8px 12px;text-align:left;"></th>
<th style="padding:8px 12px;text-align:left;">ChatGPT/Claude Projects/Gemini Gems</th>
<th style="padding:8px 12px;text-align:left;">Cursor/Claude Code</th>
</tr></thead>
<tbody>
<tr style="border-bottom:1px solid #dadce0;">
<td style="padding:8px 12px;"><strong>Memory across chat threads</strong></td>
<td style="padding:8px 12px;">Upload documents to "project knowledge." Updating is clunky: you need to delete and re-upload each document.</td>
<td style="padding:8px 12px;">Memory lives in text files that are continuously updated, directly inline, throughout a conversation with AI.</td>
</tr>
<tr style="border-bottom:1px solid #dadce0;">
<td style="padding:8px 12px;"><strong>Chat threads</strong></td>
<td style="padding:8px 12px;">Conversations with AI store a lot of history, need to run long.</td>
<td style="padding:8px 12px;">Conversations with AI constantly update project files, so they stay short and disposable.</td>
</tr>
</tbody></table>
<img src="/magicschoolbus/images/image46.png" alt="" style="max-width:100%;height:auto;">
<p>*</p>
</body>
</html>
