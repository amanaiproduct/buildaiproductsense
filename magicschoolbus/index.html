<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>How to build AI product sense</title>
<style>
  body {
    max-width: 720px;
    margin: 40px auto;
    padding: 0 24px;
    font-family: "Google Sans", Roboto, Arial, sans-serif;
    font-size: 16px;
    line-height: 1.7;
    color: #1a1a1a;
    background: #fff;
  }
  h1 {
    font-size: 2em;
    margin: 1.2em 0 0.4em;
    line-height: 1.25;
    font-weight: 700;
  }
  h2 {
    font-size: 1.6em;
    margin: 1.4em 0 0.5em;
    line-height: 1.3;
    font-weight: 600;
  }
  h3 {
    font-size: 1.25em;
    margin: 1.4em 0 0.5em;
    line-height: 1.35;
    font-weight: 600;
  }
  h4 {
    font-size: 1.1em;
    margin: 1.2em 0 0.4em;
    line-height: 1.4;
    font-weight: 600;
  }
  p {
    margin: 0 0 1em;
  }
  a {
    color: #1a73e8;
    text-decoration: none;
  }
  a:hover {
    text-decoration: underline;
  }
  img {
    max-width: 100%;
    height: auto;
    display: block;
    margin: 1.2em auto;
    border-radius: 4px;
  }
  ul, ol {
    margin: 0 0 1em;
    padding-left: 2em;
  }
  li {
    margin-bottom: 0.5em;
  }
  code {
    background: #f1f3f4;
    padding: 2px 6px;
    border-radius: 3px;
    font-family: "Roboto Mono", monospace;
    font-size: 0.9em;
  }
  pre {
    background: #f8f9fa;
    padding: 16px;
    border-radius: 8px;
    overflow-x: auto;
    font-family: "Roboto Mono", monospace;
    font-size: 0.9em;
    line-height: 1.5;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  table {
    font-size: 0.95em;
  }
  hr {
    border: none;
    border-top: 1px solid #dadce0;
    margin: 2em 0;
  }
  blockquote {
    border-left: 3px solid #dadce0;
    margin: 1em 0;
    padding: 0.5em 1em;
    color: #5f6368;
  }
  strong {
    font-weight: 600;
  }
</style>
</head>
<body>
<h1>How to build AI product sense</h1>
<h2>The secret is using Cursor for non-technical work (with 75 free days of Cursor Pro!)</h2>
<p><img src="/magicschoolbus/images/image1.png" alt="" style="max-width:100%;height:auto;"> Youâ€™re in a product meeting and someone mentions â€œsubagentsâ€ or â€œcontext engineeringâ€ or â€œagent memory.â€ You nod along. You know what these terms mean â€¦ youâ€™re just hoping no one expects you to use them in a sentence.</p>
<p>Youâ€™ve watched the video explainers, bookmarked the infographics, vibe coded a few apps, and even shipped an AI feature. So why does it still feel like youâ€™re miles from truly understanding all this stuff?</p>
<p>We (Tal and Aman) have both been there, over and over again while building AI products for tens of thousands of customers. The problem isnâ€™t you. The problem is the â€œAI hype industrial complex.â€ Most AI content is designed to induce FOMO, not to teach: â€œThis model is INSANEâ€ posts, demos that hide the messy reality, and diagrams that complicate more than they explain.</p>
<p><strong>We found that the single most transformative habit to internalize important AI concepts was to move away from consumer-grade UIs (ChatGPT, Granola, Lovable) and into more powerful AI coding agents like Cursor and Claude Code.</strong> Getting our hands dirty with coding agents has helped us build our â€œAI product senseâ€â€”the ability to correctly anticipate what will be truly impactful for users and also feasible with AI.</p>
<p>AI product sense is encountering support tickets about AI â€œforgettingâ€ facts, and recognizing it as context rot. Or watching a user struggle through a workflow and confidently saying that agent memory solves thisâ€”and knowing how to re-structure the experience.</p>
<p>Weâ€™ve learned more about how AI products actually work in the past three months by using Cursor for daily (non-technical) tasks than in three years of using ChatGPT. This is because coding agents transparently show their work. You can read AIâ€™s reasoning, inspect the tool calls, and watch the context window fill up. You hit the same walls as engineers building AI applications, naturally intuit your own solutions, and start anticipating trends and industry announcements.</p>
<p>We now spend our days using Cursor (and Claude Code) for daily, non-technical work: strategy, prioritization, decision-making, data analysis, and productivity. They serve as our thinking partner and personal operating system.</p>
<p>In this post, weâ€™ll guide you through using AI coding agents for your non-technical product work:</p>
<ul><li>In steps 1-4 weâ€™ll <strong>get set up and familiar with Cursor</strong> with a fun Disney-themed exercise</li><li>In steps 5-6 weâ€™ll <strong>use Cursor to get hands-on with choosing AI models and calling tools</strong></li><li>In steps 7-10, <strong>weâ€™ll build a lightweight personal OS</strong> (i.e. your own AI product you can use daily) and then improve it with RAG, memory, and context engineering</li></ul>
<p>Youâ€™ll walk away with the confidence to anticipate the technology instead of chasing it and, as a bonus, a personal AI operating system. <strong>Together weâ€™ll build our AI product sense.</strong></p>
<h3>Step 1: Download Cursor</h3>
<p>Cursor is hands-down the best coding agent to most quickly ramp up your AI product sense.</p>
<p>Youâ€™re probably hearing about Claude Code all over, and we love it for delegating long-running independent tasks like vibe coding. Cursor is still our favorite for <em>pairing</em> with AI and being able to directly watch an AI agent at work.</p>
<p>Cursor is a visual, clickable user experience and can be used with a variety of AI model providers including OpenAI and Anthropic. That means you can very likely use it at work.</p>
<p>Downloading Cursor will take you two minutes. <strong>Do it right now.</strong></p>
<ol><li><a href="https://cursor.com/download">Download and install Cursor</a>. <strong>For this post, make sure to download and install the desktop app, not the web version of Cursor.</strong></li></ol>
<img src="/magicschoolbus/images/image2.png" alt="" style="max-width:100%;height:auto;">
<h3>Step 2: Create a new project</h3>
<p>Open Cursor, sign up, power through the onboarding flow, and click â€œOpen project.â€</p>
<p><em>If youâ€™ve already used Cursor before, click <strong>File > New Window</strong> to get to this screen and open a new project.</em></p>
<img src="/magicschoolbus/images/image3.png" alt="" style="max-width:100%;height:auto;">
<p>Click â€œNew Folderâ€:</p>
<img src="/magicschoolbus/images/image4.png" alt="" style="max-width:100%;height:auto;">
<p>Name it â€œBuild AI Product Senseâ€ and click â€œCreateâ€:</p>
<img src="/magicschoolbus/images/image5.png" alt="" style="max-width:100%;height:auto;">
<p>And finally, click â€œOpenâ€ (yes, itâ€™s unusual to click Open on an empty folder, but just do it; itâ€™ll work):</p>
<img src="/magicschoolbus/images/image6.png" alt="" style="max-width:100%;height:auto;">
<h3>Step 3: Continue this post inside Cursor</h3>
<p>Strap in, because youâ€™re going to continue the experience inside Cursor itself, inspired by the childrenâ€™s science show <a href="https://www.youtube.com/watch?v=-azpNkFZs1Q"><em>The Magic School Bus</em></a>.</p>
<p><em>If you donâ€™t have time to ride the Magic School Bus right now, you can keep reading below. However, to build your AI product sense, we recommend you come back and try continuing this post inside Cursor using the prompt below.</em></p>
<p>Make sure youâ€™re in â€œAgentâ€ mode. This allows Cursor to take actions (such as fetching this post from the internet).</p>
<img src="/magicschoolbus/images/image7.png" alt="" style="max-width:100%;height:auto;">
<p>In the â€œmodelâ€ dropdown, turn off â€œautoâ€ and select <em>Opus 4.5</em> ğŸ§ : <img src="/magicschoolbus/images/image8.png" alt="" style="max-width:100%;height:auto;"></p>
<h2><strong>Side note: Weâ€™re hooking you up with free Cursor credits!</strong></h2>
<p>To help you experience the full power of Cursor during this tutorial, weâ€™re hooking up Lennyâ€™s Newsletter subscribers with $50 in free Cursor credit. This is enough to get you 2.5 months of standard usage. A huge thank-you to Ben Lang and team Cursor for making this happen. ğŸ‰</p>
<p><strong>How to get your free Cursor credits:</strong></p>
<ol><li>Visit <a href="http://Cursor.com/dashboard">Cursor.com/dashboard</a> and sign up for Cursor</li><li><a href="https://www.lennysnewsletter.com/subscribe">Become an annual (or Insider) Lennyâ€™s Newsletter subscriber</a></li><li><a href="http://LennysProductPass.com">Grab your free unique Cursor code</a> (scroll to the bottom to find â€œCursorâ€)</li><li>Click the URL and youâ€™ll see the screen below: <img src="/magicschoolbus/images/image9.png" alt="" style="max-width:100%;height:auto;"></li><li>Click â€œRedeem Nowâ€ to apply the credits to your account. <em>[Credits can be redeemed whether you have a free or paid account.]</em></li></ol>
<ol><li>Once youâ€™ve redeemed the credits, you should see this box appear in your Cursor dashboard. (If you donâ€™t see the credits, try to hard-refresh, or log out and log back in. If that doesnâ€™t work, shoot a message to <a href="mailto:hi@cursor.com">hi@cursor.com</a> and mention this post.) <img src="/magicschoolbus/images/image10.png" alt="" style="max-width:100%;height:auto;"></li></ol>
<ol><li>Finally, youâ€™ll need to upgrade to the Pro (or higher) plan to use the latest AI models like Opus 4.5. If youâ€™re already on the Pro (or higher) plan, youâ€™re all set. <img src="/magicschoolbus/images/image11.png" alt="" style="max-width:100%;height:auto;"></li></ol>
<p>Once you see the credits in your Dashboard, go ahead and upgrade. You wonâ€™t be charged anything (you have 2.5 monthsâ€™ worth of credits). The credits will be automatically applied to the next invoice (and can also be applied to â€œ<a href="https://cursor.com/docs/account/pricing#what-happens-when-i-reach-my-limit">on-demand usage</a>â€ if you enable it).</p>
<p>It should look like this: <img src="/magicschoolbus/images/image12.png" alt="" style="max-width:100%;height:auto;"></p>
<p>Then, paste the prompt below into the chat box.</p>
<p><strong>Help me build my AI product sense using this post (that I have not yet read) [Future Substack URL, for now at TODO: https://magicschoolbus.surge.sh/] (Do not open it in a browser â€” that will be distracting â€” use cURL or any other tool.)</strong></p>
<p><strong>Start by giving me an overview of why weâ€™re here and where weâ€™re going with this, so I feel super motivated to stick with it. Then pause and confirm Iâ€™m ready to start. Use the pause to learn more about my professional context (less about Cursor or AI) that could inform our journey together.</strong></p>
<p><strong>Next, walk me through each bite-size concept, in order, one step/question at a time, starting with â€œStep 3.â€</strong></p>
<p><strong>You are both a really good 1-1 tutor for hands-on learning AND the Cursor agent. Have me take action so Iâ€™m engaged and learning. Ask me one question at a time. Before starting new steps/stages/ideas/concepts, stop and check in with me and encourage me to explain it back to you â€” and hold me to a high bar â€” like an effective, empathetic tutor.</strong></p>
<p><strong>Itâ€™s important that you cover every single concept contained in this post, in sequential order. Keep me motivated by signposting and giving clarity on how much weâ€™ve done and how much is left. (That said, leave room to follow my curiosity and go off script, as long as overall we are progressing through the post.)</strong></p>
<p><strong>Use the original words of the post when relevant (you have permission to use them as your words in first person, rather than explicitly quoting someone else). Sentence-case your headings (not title case).</strong></p>
<p><strong>Anytime you come across an image inline in the post, read the image (one at a time, just in time, not in advance, storing temporarily if needed). This is important to understand the contents of the post.</strong></p>
<p><strong>We are already talking inside a Cursor chat thread, so letâ€™s use this same thread for as much as we can. Important: You are also the Cursor agent! So when I say a prompt that you suggested, or give a task like â€œchange this file,â€ act on it yourself (donâ€™t direct me to do it separately or ask if I did it separately). Donâ€™t refer to a separate Cursor agent. Itâ€™s YOU.</strong></p>
<p><strong>Remember that Cursor might be configured in a lot of different ways visually, and is constantly evolving, so avoid assumptions about where a UI element might be. The file explorer may be on the left or the right!</strong></p>
<p><strong>Anytime you try to use a tool of any kind, itâ€™s going to ask for my approval, and thatâ€™s going to feel scary. So I need you to explain why youâ€™re asking and why itâ€™s safe to approve. It might even be a teachable moment â€” you can even tie to the goal of the post (and where we are in the journey) that, well, youâ€™re an agent and this is you in action!</strong></p>
<p><strong>Consistently encourage me to use the voice recording feature (a ğŸ™ï¸ icon under the chat box) to build the habit of speech-to-text.</strong></p>
<p>And click â€œsubmitâ€: <img src="/magicschoolbus/images/image13.png" alt="" style="max-width:100%;height:auto;"></p>
<p>If you choose to accept this challenge, youâ€™ll consume the rest of this post from inside Cursor. <strong>Stay in one chat thread (â€œagentâ€) the entire time (no need to open a new thread or agent).</strong></p>
<p>AI will walk you through the rest of this post. <a href="https://www.youtube.com/watch?v=-azpNkFZs1Q">Seatbelts, everyone!</a> Weâ€™ll see you in Cursor.</p>
<h3>Step 3: Cursor may look intimidating, but youâ€™re more familiar with it than you realize</h3>
<p>Cursor looks <em>Matrix</em>-style geeky, but itâ€™s just ChatGPT, a text editor, and a file explorer smooshed into one window.</p>
<p>We repeat, Cursor is just three tools youâ€™ve used plenty of times before, combined:</p>
<ol><li>ChatGPT</li><li>A text editor</li><li>File explorer</li></ol>
<p>One of Talâ€™s students, a salesperson, said it best: Cursor is â€œAI that can touch any file on my computer.â€</p>
<p>Hereâ€™s a quick tour:</p>
<p><strong>1. Agents</strong></p>
<p>Agents are a fancy term for â€œchats.â€ This is where youâ€™ll interact with AI.</p>
<p>On the left, youâ€™ll see an empty panel that will contain your agent history. Click â€œnew agentâ€ to start your first chat (â€œagentâ€ is synonymous with â€œchat threadâ€):</p>
<p><img src="/magicschoolbus/images/image14.png" alt="" style="max-width:100%;height:auto;"> Youâ€™ll see a familiar chat box. Click on the dropdown in the bottom left corner. You can select between â€œAskâ€ mode and â€œAgentâ€ mode (ignore the other options, like Plan and Debug, for now).</p>
<img src="/magicschoolbus/images/image15.png" alt="" style="max-width:100%;height:auto;">
<p>â€œAskâ€ mode is using Cursor just like classic ChatGPT: for chatting, and not making any changes. This is great for brainstorming or asking questions, before taking any action. You can immediately start using this instead of standard ChatGPT/Claude.</p>
<p>â€œAgentâ€ mode is for when we want Cursor to modify files in our project. Weâ€™ll use this together in a moment.</p>
<p><strong>2. Editor</strong></p>
<p>Weâ€™ll use this panel to view and manually edit text files. This is the same as using Text Edit on a Mac or Notepad on Windows. To see the text editor, you might have to create a new file, or double-click on an existing file.</p>
<img src="/magicschoolbus/images/image16.png" alt="" style="max-width:100%;height:auto;">
<p><strong>3. File explorer</strong></p>
<p>The file explorer shows all the files and folders in your project. This is the same as Finder on a Mac, or File Explorer on Windows, and it may be on the right or left of Cursor depending on the latest version. To expand it, you might have to click the small icon at the top of the window to make it visible. (You can always use <code>Ctrl + B</code> on Windows or <code>Cmd + B</code> on a Mac.)</p>
<p><img src="/magicschoolbus/images/image17.png" alt="" style="max-width:100%;height:auto;"> Even if Cursor feels intimidating at first, the <a href="https://www.lennysnewsletter.com/p/build-your-personal-ai-copilot">core concepts</a> are the same as any LLM youâ€™ve already used. Cursor just has a bit more configurability, options, and things you can play with. This is your playground to build intuition.</p>
<h4>Cursor is our choice for getting real work done, not just learning AI concepts</h4>
<p>If youâ€™ve already <a href="https://www.lennysnewsletter.com/p/build-your-personal-ai-copilot">created your AI thinking partner</a> inside ChatGPT or Claude projects, youâ€™re probably wondering if itâ€™s worth the hassle of switching to Cursor. Itâ€™s important for us to say that regardless of understanding technical concepts, we now spend most of our days in coding agents for non-technical tasks.</p>
<p>So whatâ€™s the practical difference, and why did we make the switch? First, Cursor is fundamentally the same idea as ChatGPT projects: files as knowledge, chat as interface, and instructions that always apply.</p>
<p>Two small form-factor differences change everything:</p>
<ul><li>You drag and drop specific files/folders into each chat (selective context)</li><li>The AI edits your files directly (malleable knowledge)</li></ul>
<p>These create a tight loop where every chat automatically improves your project knowledge (but only when you tell the agent to do so). In ChatGPT projects, history and outputs live in long chats. You manually copy things back to project knowledge. In Cursor, outputs live in documents and chats become disposable one-offs because the value lives in documents, not in conversation history.</p>
<p>The main takeaway here is that your knowledge base will cover more ground, and update more frequently, because youâ€™re using the personal OS to build and edit context every single day.</p>
<h3>Step 4: Create a Disney song parody to learn the basics of Cursor</h3>
<p>Weâ€™ll start by creating a new blank file in Cursor. Hover your mouse in the file explorer, and click the â€œNew Fileâ€ button:</p>
<img src="/magicschoolbus/images/image18.png" alt="" style="max-width:100%;height:auto;">
<p>Name your file <strong>lyrics.txt</strong>:</p>
<img src="/magicschoolbus/images/image19.png" alt="" style="max-width:100%;height:auto;">
<p>Next, search the web for your <a href="https://www.google.com/search?q=youre+welcome+lyrics">favorite Disney song</a> (googling the title usually prints the lyrics). Copy the words to your clipboard: <img src="/magicschoolbus/images/image20.png" alt="" style="max-width:100%;height:auto;"></p>
<p>Back in Cursor, paste them into the file you just created, and save the file: <img src="/magicschoolbus/images/image21.png" alt="" style="max-width:100%;height:auto;"> Next, switch to â€œAgentâ€ mode in the chat box:</p>
<p><img src="/magicschoolbus/images/image22.png" alt="" style="max-width:100%;height:auto;"> Finally, type in <code>Change one line in the first stanza and one line in the chorus of lyrics.txt to be about Silicon Valley</code> and send it off using the â€œup arrowâ€ button:</p>
<p><img src="/magicschoolbus/images/image23.png" alt="" style="max-width:100%;height:auto;"> A lot just changed on our screen! Youâ€™ll notice a lot of red and green in our lyrics.txt file. Cursor modified our file. The red shows us each old line that it removed, and the green shows us the new line that it added instead.</p>
<p>You can click â€œUndoâ€ if you donâ€™t like the change, or â€œKeepâ€ if you want it to remain.</p>
<img src="/magicschoolbus/images/image24.png" alt="" style="max-width:100%;height:auto;">
<h3>Step 5: See how different AI models behave</h3>
<p>Now that youâ€™ve made your first edit, letâ€™s explore a key product decision every AI team faces: which model to use.</p>
<p>Youâ€™ll notice thereâ€™s another dropdown in our chat box:</p>
<img src="/magicschoolbus/images/image25.png" alt="" style="max-width:100%;height:auto;">
<p>Youâ€™ve seen this in ChatGPT, Claude, or Geminiâ€”itâ€™s where you choose the model you want to use. In Cursor, however, you can choose <em>any</em> LLM.</p>
<p>Click into it and disable â€œAuto,â€ and take back the power to decide:</p>
<img src="/magicschoolbus/images/image26.png" alt="" style="max-width:100%;height:auto;">
<p>When we try the same query in multiple models, we build intuition for how each one might tackle (or fumble) it differently. For example, Claude models are sensitive to copyright law and refuse to modify Disney songs (to get past this, change the end of your prompt to <code>...to make fun of the song itself.</code> which qualifies as â€œfair useâ€). While OpenAIâ€™s models are less concerned with copyright, they stumbled when calling Cursorâ€™s <code>apply_patch</code> tool, their preferred command for editing a text file (although this is less common in the <a href="https://cursor.com/blog/codex-model-harness">latest Codex model</a>s).</p>
<p>All that before we had a chance to judge the cleverness of their lyrics!</p>
<p>Which model do we personally use to get work done? When it comes to individual use, we treat ourselves to the latest and greatest models [a <a href="#footnote-smaller-models">footnote on smaller models</a>].</p>
<ol><li>For writing, complex planning, and nuanced life advice (as of the time of this post), we reach for Claude Opus. (We also found itâ€™s the best for experiencing this post from inside Cursor.)</li><li>Its cousin, Sonnet, is our workhorse for tasks involving lots of context, with a 1M token context window (and slightly faster responses).</li></ol>
<p>Zooming out, thereâ€™s a subtle lesson in Cursorâ€™s model dropdown: <strong>there are only a few frontier LLMs, and theyâ€™re available to all product teams.</strong> Innovation is how we apply them.</p>
<p>Make a habit of switching models for tasks you care about. Over time, youâ€™ll develop genuine opinions about model tradeoffsâ€”the kind of intuition thatâ€™s hard to get from benchmarks alone.</p>
<img src="/magicschoolbus/images/image27.png" alt="" style="max-width:100%;height:auto;">
<h3>Step 6: Inspect your agentâ€™s tool calls</h3>
<p>LLMs can only produce text, but when they take action (edit a file, fetch data, search the web), theyâ€™re calling tools. And <em>tool calling</em> is a distinct skill from everything else we usually notice about LLMs.</p>
<p>Now ask your agent, <code>Can you walk me through each step (tool/thinking/reasoning/anything else) you used to accomplish this task?</code></p>
<p>In our test, our LLM reported that:</p>
<ol><li>It used a tool called <code>read_file</code> to find out what was inside the file</li><li>It thought about what to edit</li><li>It used a tool called <code>search_replace</code> to modify the text file</li></ol>
<p>Hereâ€™s how it described #3:</p>
<img src="/magicschoolbus/images/image28.png" alt="" style="max-width:100%;height:auto;">
<p>Donâ€™t let this toolâ€™s foreign name repel you. Youâ€™ve done â€œsearch and replaceâ€ plenty of times in Microsoft Word or Google Docs. And youâ€™ve definitely â€œread a fileâ€ before.</p>
<p>(By the way, this is another place where models differ in approach! Gemini consistently accomplished this in three tool calls, while Opus used two. Try it out and see for yourself.)</p>
<p>Coding agents do most of their work with a small set of tools for file navigation and text editing. To see the full set, ask it to <code>List every tool available to you.</code></p>
<img src="/magicschoolbus/images/image29.png" alt="" style="max-width:100%;height:auto;">
<p>Most of these tools have familiar names; youâ€™ve definitely read the contents of a directory and deleted files before. Others, like <code>read_lints</code> and <code>run_terminal_cmd</code>, are more common in software development (although coding agents can employ them for <a href="https://www.lennysnewsletter.com/p/everyone-should-be-using-claude-code">non-technical requests</a> too).</p>
<p>How does the LLM actually call the tool? An LLM canâ€™t run commands on your computer, so it relies on <em>Cursor</em> to do so. Think of it like hiring a handyman. The LLM describes what it wants done, but it canâ€™t hold the hammer. Cursor is the handyman: it hears the LLMâ€™s request, uses the tool, and brings back the result so it can decide what to do next.</p>
<p>Cursor recognizes when the LLM prints a tool name (such as above), and executes that tool on your computer. After the tool finishes running, Cursor returns the result to the LLM (e.g. a successful result, or an error message) so the LLM can decide what to do next. (If youâ€™ve heard the terms â€œMCP clientâ€ or â€œagent harness,â€ those both describe Cursorâ€™s role here.)</p>
<p>The way an LLM interacts with <em>tools</em> is eerily similar to how it interacts with <em>humans</em>. If we view â€œclassic ChatGPTâ€ as a DM thread between an LLM and a human, then AI agents are a <a href="https://www.talraviv.co/p/ai-agents-whatsapp-group?utm_source=publication-search">three-way group chat between an LLM, a human, and tools</a>.</p>
<p>Now when someone asks, â€œCan our agent do X?â€ youâ€™ll instinctively think, â€œWhat tools would it need, and how good is our model at calling them?â€ This also connects back to model selection: itâ€™s not just â€œsmartest model wins.â€ Tool calling <a href="https://surgehq.ai/blog/rl-envs-real-world">is its own skill</a>, separate from reasoning or writing quality.</p>
<h4>Wait, then whatâ€™s the â€œMCPâ€ I keep hearing about?</h4>
<p>For most organizations, the most valuable data doesnâ€™t live in local text files but rather in external SaaS services. For an LLM to interact with Linear, Figma, Notion, Snowflake, BigQuery, Amplitude, or Mixpanel, those services need to provide the LLM with <em>custom tools</em>.</p>
<p>Normally, each SaaS company would have to integrate a separate tool for each LLM out there. To avoid this mess, the industry adopted a standard called Model Context Protocol (MCP). That way, each SaaS company now only needs to build one connector that works everywhere.</p>
<p>If that sounds a lot like USB or Bluetooth, thatâ€™s the right analogy. To continue the comparison: most agent tools arenâ€™t MCP, just like most electrical wires arenâ€™t shaped like USB plugs. <strong>For simplicity, MCP is just another tool the agent can use, with a standardized interface.</strong></p>
<h3>Step 7: Put everything into practice by building your personal OS inside Cursor</h3>
<p>Now that we understand how agents work generally, letâ€™s create a personalized AI agent for ourselves to see how the components of Cursor come together.</p>
<p>Weâ€™re going to build a very lightweight, minimal personal productivity system that organizes our contacts from various parts of our life, like notes, transcripts, and unstructured thoughts, as well as some tasks that we need to get done. (This lets us temporarily ignore discovery, distribution, and pricing. Weâ€™ll be free to focus on whatâ€™s technically possible.)</p>
<p>By the end of this exercise, youâ€™ll be able to ask Cursor to create tasks from your backlog and get started on those tasks based on the context you provided in the knowledge and goals. In the process, weâ€™ll learn about RAG, memory, and context engineering and build critical parts of product sense.</p>
<p>To get started, you can copy and paste the following prompt into Cursor (make sure youâ€™re on â€œAgentâ€ mode):</p>
<p><strong>Create a minimal personal productivity system:</strong></p>
<pre><strong>## Structure
â”œâ”€â”€ Knowledge/        # Notes, research, thinking
â”œâ”€â”€ Tasks/            # Action items as Markdown files
â”œâ”€â”€ GOALS.md          # Goals and priorities
â””â”€â”€ AGENTS.md         # AI assistant instructions

## AGENTS.md should instruct the AI to:
- Be a productivity assistant for goals and tasks
- Never write code â€” only Markdown
- Keep tasks tied to goals
- Suggest max. 3 daily priorities when asked
- Be direct and concise

## After creating:
1. Say: "Created your workspace with Knowledge/, Tasks/, GOALS.md, and AGENTS.md"
2. Ask: "What are your current goals? Once you share them, I'll add them to GOALS.md"
3. Ask: "What tasks are you working on? I'll create initial task files in Tasks/ linked to your goals"
4. Populate GOALS.md and Tasks/ from answers</strong></pre>
<p>(Optionally, you can <a href="https://github.com/amanaiproduct/personal-os">clone the personal OS</a><em>. Hint</em>: you can copy and paste this into your Cursor chat and ask it to clone the repo as well.) <img src="/magicschoolbus/images/image30.png" alt="" style="max-width:100%;height:auto;"></p>
<p>Cursor should create two directories (folder): Tasks and Knowledge. It will also create a <code>GOALS.md</code> file, which should be your personal goals. At this point, Cursor will ask you a couple of follow-up questions to start to populate your personal OS with <strong>context</strong>, like â€œWhat are your goals?â€ and â€œWhat are you working on?â€</p>
<p>Congrats! Youâ€™re now the PM of your own AI product. In the next few sections, weâ€™ll use it to experience RAG, agent memory, and context engineering firsthand. Except now youâ€™ll feel them instead of just reading about them.</p>
<h3>Step 8: Kicking the tires of retrieval augmented generation (RAG) with your personal OS</h3>
<p>When an AI product gives wrong answers, the instinct is to blame the model. Before you reach for a larger model or expensive fine-tuning, ask: does the agent even have the right information?</p>
<p>Letâ€™s ask Cursor, â€œ<strong>Whatâ€™s in this repo? Explain it to me as a product manager:â€</strong> and see what it responds with.</p>
<p>ğŸ’¡This prompt is insanely powerful for just about any repo or folder you open with Cursor and Claude Code. We recommend starting here when opening any new codebase.</p>
<p><a href="https://help.openai.com/en/articles/8868588-retrieval-augmented-generation-rag-and-semantic-search-for-gpts">RAG</a> is a fancy term for â€œBefore I start talking, I gotta go look everything up and read it first.â€ Despite the technical name, youâ€™ve been doing it your whole life. Before answering a hard question, you look things up. Agents do the same.</p>
<p>In our case, our agent will <a href="https://cursor.com/blog/semsearch">search</a> on top of your files and folders, to provide context to the LLM. There are a lot of different ways LLMs can search files within a codebase, or even find data from the internet to use in your response. At the end of the day, whether itâ€™s Perplexity, Google AI Mode, Claude Code, Cursor, or anything out there youâ€™ve seen with the term â€œRAG,â€ it's some mechanism that pulls documents and starts the chat with those documents [a <a href="#footnote-claude-code">footnote about Claude Code</a>].</p>
<img src="/magicschoolbus/images/image31.png" alt="" style="max-width:100%;height:auto;">
<p>You can also tag specific files within Cursor using the @ symbol, if you want the agent to reference specific pieces of context.</p>
<img src="/magicschoolbus/images/image32.png" alt="" style="max-width:100%;height:auto;">
<p>RAG fills the context window with whatâ€™s relevant right now. But some context (who you are, how you like to work) should be there every time. Thatâ€™s where memory comes in.</p>
<h3>Step 9: Adding agent memory with AGENTS.md</h3>
<p>LLMs are stateless, so we like to think of them as Mensa geniuses with the short-term memory of a hamster. Every new chat thread is a blank slate, so if you want continuity, you have to engineer it. As PMs, we have to ask: what should persist, and how?</p>
<p>A form of context you may have heard of in relation to AI agents is <strong>memory</strong>. Memory might include facts about us but also preferences as to how we want our LLMs to behave and interact with us. We also might want to be more intentional and proactive about how we curate our AIâ€™s memory.</p>
<p>All coding agents today follow a convention called <a href="http://AGENTS.md">AGENTS.md</a>. This is a Markdown file that, if found in any directory, is automatically appended at the top of every chat thread.</p>
<p>(Quick disambiguation: AGENTS.md is not â€œsubagents.â€ Subagents are when one chat thread spawns another chat thread to handle a subtask. AGENTS.md is just instructionsâ€”it doesnâ€™t spawn anything. Think of AGENTS.md as a â€œsticky note on every conversationâ€ and subagents as â€œdelegating to a colleague.â€)</p>
<p><strong>Let that sink in: memory is just a text file prepended to every conversation</strong>. Thereâ€™s no magic here. But that also means memory has a costâ€”whatever you put in AGENTS.md takes up context window space in every single chat. Too much memory, and you have less room for everything else. This is why you want to be intentional about what goes in memory (persistent, always relevant) vs. what you retrieve on demand with RAG (task-specific).</p>
<p>Examples of what you might find in a thinking partnerâ€™s AGENTS.md:</p>
<ul><li>Who I am as a user and what this thinking partner is helping me with (e.g. â€œIâ€™m a product manager working at Acme Inc. on the platform teamâ€)</li><li>How I want to work together (e.g. â€œAsk me questions to gain more context, fill in important missing information, and challenge my assumptionsâ€)</li><li>Values to apply (e.g. â€œbias to action, make decisions with incomplete informationâ€)</li><li>How to output (e.g. â€œwrite extremely succinctly, flat hierarchy, no bold or italics, no em dashesâ€)</li></ul>
<p>By curating your own AGENTS.md, you start to feel whatâ€™s actually useful vs. noise. And thatâ€™s exactly the intuition you need when designing memory for your users.</p>
<p>Memory, RAG, tool definitions, conversation historyâ€”they all take up context. Now that you understand what each does, the next question is: how do you fit everything into a finite window? Thatâ€™s context engineering.</p>
<h3>Step 10: Context engineering for your personal OS</h3>
<p>Anytime youâ€™ve dragged a file into ChatGPT, said something that became part of its memory, started a conversation with deep research, or created a project with special instructions and knowledge, you were doing <strong>context engineering</strong>.</p>
<p>Even though youâ€™re using Cursor instead of ChatGPT, youâ€™ll still start each thread by asking, â€œWhat context does this conversation need?â€ For example, writing a PRD might start by dragging and dropping any of the following into the Cursor window:</p>
<ul><li>A folder of user research transcripts</li><li>An existing marketing landing page or sales deck</li><li>An academic research paper or technical documentation</li><li>Enabling an MCP tool connected to your analytics provider</li><li>A saved set of instructions you want to apply</li><li>A request to search for any other relevant information</li><li>An area of your productâ€™s codebase</li></ul>
<p>Try this out for yourself: Drag and drop a few PDFs, Markdown files of Google Docs, or Word docs that you might be working on into this Knowledge folder in Cursor, and ask Cursor to expand on one of the topics or ask you questions about it before getting to work.</p>
<p>Putting it all together, you might start a Cursor chat thread this way:</p>
<img src="/magicschoolbus/images/image33.png" alt="" style="max-width:100%;height:auto;">
<p><strong>Prompt for Cursor: I want you to expand on this @file (replace with your actual file, like this post). I want you to be a partner for me and ask me one question at a time as we are converging on how to approach this. I would love it if you could search for anything else thatâ€™s relevant to this document. You can also create some follow-up ideas for me to explore and turn those into tasks.md files in the Tasks folder, based on our discussion.</strong></p>
<p>Context engineering happens in two ways in Cursor: (1) what you choose to include each time you start a chat (dragging files, enabling tools) and (2) what gets automatically included every time (like AGENTS.md, MCPs, or tools). Thatâ€™s a lot of context!</p>
<p>Context is a scarce resource: LLMs have a hard limit on the amount of text (i.e. tokens) an LLM can handle. This is called a â€œcontext window.â€</p>
<p>In a conversational LLM chat bot (like ChatGPT or Claude), context increases each turn of the conversation as the LLMâ€™s last response becomes part of the next turnâ€™s input. If youâ€™ve ever gotten a notification that you hit the limit of your chat, youâ€™ve probably hit a context window:</p>
<p><img src="/magicschoolbus/images/image34.png" alt="" style="max-width:100%;height:auto;"> <a href="https://platform.openai.com/docs/guides/conversation-state?api-mode=responses">https://platform.openai.com/docs/guides/conversation-state</a></p>
<p>Coding agents are delightfully transparent about how much of your context window youâ€™ve used. In Cursor, hover your mouse over the little pie chart just beneath the chat box (you might have to increase the width of the chat pane to see it).</p>
<img src="/magicschoolbus/images/image35.png" alt="" style="max-width:100%;height:auto;">
<p>We watch it like a carâ€™s gas tank. This helps us intuitively understand what a 200K token or 1M token context window actually feels like, and how quickly it actually runs out. The best way to understand a specific carâ€™s gas mileage is to drive that car.</p>
<p>In an agentic LLM application, the context window might contain a whole lot more:</p>
<p><img src="/magicschoolbus/images/image36.png" alt="" style="max-width:100%;height:auto;"> <a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents</a></p>
<p>Does Anthropicâ€™s diagram now feel familiar? Even though itâ€™s about AI applications, itâ€™s remarkably similar to our earlier example of writing a PRD. How cool is that?</p>
<p>When you set up AI to do its best work within its limited context window, youâ€™re doing â€œcontext engineering.â€</p>
<p><img src="/magicschoolbus/images/image37.png" alt="" style="max-width:100%;height:auto;"> <a href="https://x.com/karpathy/status/1937902205765607626?lang=en">https://x.com/karpathy/status/1937902205765607626?lang=en</a></p>
<p>Tool definitions, RAG, memory, goals: they all compete for the same limited context window. How you fill that window determines how well your agent performs. This is the same tradeoff every AI engineering team faces when building production appsâ€”except now youâ€™re feeling this problem firsthand. Thereâ€™s no perfect formula for this. What goes in depends on the task, the model, and what youâ€™re trying to achieve. You develop intuition through trial and error (and regularly using your personal OS).</p>
<h4><strong>Watch out for â€œcontext rotâ€</strong></h4>
<p>As you use more and more context, youâ€™ll notice that your threads may get dumber and more forgetful as you use more tokens, and long before you get close to the maximum. The term for this is <a href="https://research.trychroma.com/context-rot">context rot</a>. In short, model performance degrades the more tokens you stuff into the context window.</p>
<p>Context rot is a fuzzy phenomenon. How badly you feel it will depend on the task at hand, as well as the particular modelâ€™s training. Youâ€™ll feel context rot (and degraded performance) less in use cases like creative brainstorming and more in precision financial, coding, or data analysis.</p>
<p>The best way to get a feel for context rot is by using an LLM for tasks you genuinely care about. Try to keep an eye on Cursorâ€™s token counter and, as it gets fuller, notice the quality of the outputs. With more context in a thread, is the agent getting better or worse? What if you try a new thread? We found this to be a fun, addictive game, kind of like driving a hybrid car and noticing when itâ€™s switching from battery to gasoline. Along the way, you build an intuition that goes further than any academic graphs.</p>
<h3>Conclusion</h3>
<p>For us, the shift to really, truly understanding AI products happened when we watched agents work day after day. Cursor allowed us to observe an AI model meander through a task: read our context, run RAG, try a tool call, hit an error, reason, try another tool...</p>
<p>Thatâ€™s when it clicked: Cursor is just an AI product like any other, composed of text, tools, and results flowing back into more textâ€”except Cursor runs locally on our computer, so we can watch it work and learn. Once we were able to break down any AI product into these same building blocks, our AI product sense came naturally. Now that youâ€™ve read this post, you can too.</p>
<p>When something impressive drops, you can now take a breath and decompose it. An <a href="https://www.youtube.com/watch?v=BER3EhUIyz0">agent that plays Settlers of Catan</a> for 75 minutes. Granolaâ€™s <a href="https://www.granola.ai/blog/how-we-wrote-the-prompts-behind-granolas-crunched-2025">eerily personalized year in review</a>. Someoneâ€™s <a href="https://clawd.bot/">WhatsApp bot</a> that browses the web with their cookies. Even (or especially) <a href="https://claude.com/blog/cowork-research-preview">Claude Cowork</a>. You can simply ask yourself: How would I reproduce that inside Cursor? If I had to â€œWizard of Ozâ€ it on my computer, what familiar parts would I assemble? The magic is still delightful, just without the mystique and FOMO.</p>
<p>The best ideas happen when intuition for people and technology coexist inside one brain. When you use coding agents daily, you start to feel whatâ€™s easy, whatâ€™s hard, and what just became feasible. In Paul Buchheitâ€™s words, when you truly understand AI products, youâ€™ll â€œlive in the future.â€</p>
<h3>CTAs</h3>
<ul><li>[In T-9 days following post publish] Our workshop <a href="https://bit.ly/4k8CLBp">â€œBuild AI Product Senseâ€</a> [I added LENNYSLIST promo code to URL] hit #1 on Maven when it launched, and the next cohort starts in 9 days. <em>Get $100 off and $1,395 in free credits to level up your workflow with Superhuman, Linear, Sprig, Dovetail, and Gamma.</em></li><li>If youâ€™re in between jobs or a university student, <a href="https://forms.gle/ehc2cVWH6hX34SaQ6%20">we have something special for you too</a>.</li><li>[In T-6 days following post publish] To get a taste, join our free lightning lesson â€œ<a href="https://maven.com/p/593d71/how-to-know-what-ai-products-to-build">How to know what AI products to build</a>â€ together with Hilary Gridley</li><li>Check out Talâ€™s <a href="https://talraviv.co/">63 free video tutorials</a> on using AI agents at work, his guest post on <a href="https://www.lennysnewsletter.com/p/build-your-personal-ai-copilot">building your AI thinking partner</a>, and his <a href="https://www.lennysnewsletter.com/p/the-super-ic-pm-tal-raviv">episode on Lennyâ€™s Podcast</a>. You can also book Tal for an <a href="https://talraviv.co/build-sprints">AI build sprint</a> with your team.</li><li>Check out Amanâ€™s <a href="https://amankhan1.substack.com/">Substack</a> for up-to-date AI PM workflows, his <a href="https://www.lennysnewsletter.com/p/beyond-vibe-checks-a-pms-complete">guest post on evals</a>, and his <a href="https://youtu.be/E_rNotqs--I?si=Ca1HhPjvGdPccoNx">podcast episode on AI PMing</a>. You can also book Aman for a workshop with your team.</li></ul>
<h3>[FOOTNOTE] Creative solutions to context limits [link footnote from Step 10, after the phrase "There's no perfect formula for this."]</h3>
<p>To avoid packing everything into the context window up front, AI engineers constantly devise all sorts of creative solutions. Here are just a few:</p>
<ul><li>â€œProgressive disclosureâ€ is the art of pulling in frameworks, tools, or instructions only when theyâ€™re needed instead of up front. This can happen manually (like when we decide to drag in a file mid-conversation), and it can happen automatically by letting the LLM decide. <a href="https://www.lennysnewsletter.com/p/claude-skills-explained">Claude Skills</a> is a great example of this.</li><li>â€œSubagentâ€ is a <a href="https://cursor.com/docs/context/subagents">fancy</a> <a href="https://platform.claude.com/docs/en/agent-sdk/subagents">term</a> for opening a new chat thread, prompting it for a subtask, and sending just the â€œbottom lineâ€ result back to the original chat thread. That way, the context window stays a bit cleaner. (This is similar to a tool call, with the job being done by an LLM.)</li><li><a href="https://blog.fsck.com/2025/12/27/streamlinear/">Condensing</a> MCP tools into a single tool, or <a href="https://www.anthropic.com/engineering/code-execution-with-mcp">giving the agent freedom</a> to select (and combine) tools on the fly.</li><li><a href="https://youtu.be/6_BcCthVvb8?si=yB3nQucUnnkdvl4o&t=900">Pruning</a> or <a href="https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents">summarizing</a> the context window as you near its limit. If youâ€™ve ever run out of room in a chat thread and asked the LLM to summarize so you can start a fresh threadâ€”youâ€™ve already done this yourself.</li></ul>
<p>These strategies allow AI applications to break out of the zero-sum game of context limits, to keep agents running autonomously on complex tasks for <a href="https://youtu.be/BER3EhUIyz0">as long as possible</a>. This is where AI engineering gets fun and creative. The best part is that no one has fully figured this out, and ideas are constantly evolving.</p>
</body>
</html>
